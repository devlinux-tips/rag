# Modern TypeScript + Python Integration Architecture

**Date**: 2025-09-23
**Status**: Ideation Phase
**Authors**: Claude Flow Swarm Research
**Context**: Ground-up build with Python RAG backend + TypeScript API layer

## Overview

This document explores modern integration patterns for building a RAG system with Python backend services and TypeScript frontend/API layer. The goal is to leverage the strengths of both ecosystems while maintaining type safety, performance, and developer experience optimized for AI code generation.

## Current Context

- **No existing REST API** - building from ground up
- **Python RAG backend** - existing MLM/AI processing capabilities
- **TypeScript preferred** - for API layer and frontend interactions
- **Multi-tenant architecture** - as outlined in existing documentation
- **AI-friendly development** - code will be fully written by AI

## Research Findings: 2024 State of TypeScript + Python Integration

### Modern Integration Tools

1. **pydantic-to-typescript** - CLI tool for converting Pydantic models to TypeScript interfaces
2. **FastAPI + tRPC** - Hybrid approach with type-safe bridges
3. **Redis pub/sub** - Real-time communication between services
4. **Container orchestration** - Independent scaling and deployment
5. **Event-driven patterns** - Async processing with real-time updates

### Industry Trends 2024

- **Schema-first development** becoming standard
- **Type safety across language boundaries** is now achievable
- **Microservices with type bridges** replacing monolithic approaches
- **AI-friendly architectures** prioritizing clear interfaces and auto-generation

## Proposed Architecture: Dual-Layer with Type Bridge

```
┌─────────────────────────────────────────────────────────┐
│                TypeScript API Layer                    │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐     │
│  │    tRPC     │  │  Next.js    │  │  Prisma     │     │
│  │  Router     │  │   API       │  │   Client    │     │
│  └─────────────┘  └─────────────┘  └─────────────┘     │
│           │              │              │               │
│  ┌─────────────────────────────────────────────────────┐ │
│  │           Type-Safe Bridge Layer                   │ │
│  │     • pydantic-to-typescript                       │ │
│  │     • Auto-generated schemas                       │ │
│  │     • Redis pub/sub                                │ │
│  └─────────────────────────────────────────────────────┘ │
└─────────────────┬───────────────────────────────────────┘
                  │ HTTP/WebSocket + Redis
┌─────────────────┴───────────────────────────────────────┐
│                Python RAG Daemon                       │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐     │
│  │   FastAPI   │  │  Command    │  │   Vector    │     │
│  │   Server    │  │   Router    │  │   Store     │     │
│  └─────────────┘  └─────────────┘  └─────────────┘     │
│           │              │              │               │
│  ┌─────────────────────────────────────────────────────┐ │
│  │         RAG Processing Services                     │ │
│  │  • QueryService   • DocumentService                │ │
│  │  • TenantService  • HealthService                  │ │
│  └─────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────┘
```

## Design Patterns

### 1. Type-Safe Schema Generation

**Python (Pydantic Models)**
```python
from pydantic import BaseModel
from typing import List, Optional

class QueryRequest(BaseModel):
    text: str
    language: str
    tenant_id: str
    user_id: str
    rag_config: Optional[RagConfig] = None

class QueryResponse(BaseModel):
    answer: str
    confidence: float
    sources: List[str]
    response_time: float
    query_id: str

class RagConfig(BaseModel):
    max_documents: int = 5
    min_confidence: float = 0.7
    language: str = "en"
```

**Auto-Generated TypeScript**
```typescript
// Generated by pydantic-to-typescript
export interface QueryRequest {
  text: string;
  language: string;
  tenant_id: string;
  user_id: string;
  rag_config?: RagConfig;
}

export interface QueryResponse {
  answer: string;
  confidence: number;
  sources: string[];
  response_time: number;
  query_id: string;
}

export interface RagConfig {
  max_documents?: number;
  min_confidence?: number;
  language?: string;
}
```

### 2. tRPC Router with Python Backend Integration

```typescript
import { router, procedure } from '@trpc/server';
import { QueryRequest, QueryResponse } from './generated-types';
import { PythonRagClient } from './python-client';

const pythonRagClient = new PythonRagClient('http://localhost:8080');

export const appRouter = router({
  rag: router({
    query: procedure
      .input(QueryRequest)
      .mutation(async ({ input }): Promise<QueryResponse> => {
        return await pythonRagClient.query(input);
      }),

    processDocuments: procedure
      .input(ProcessDocumentsRequest)
      .mutation(async ({ input }) => {
        const taskId = await pythonRagClient.processDocuments(input);
        return { taskId, status: 'started' };
      }),

    getTaskStatus: procedure
      .input(z.object({ taskId: z.string() }))
      .query(async ({ input }) => {
        return await pythonRagClient.getTaskStatus(input.taskId);
      })
  }),

  tenant: router({
    create: procedure
      .input(CreateTenantRequest)
      .mutation(async ({ input }) => {
        // Dual database approach: Prisma for metadata, Python for RAG setup
        const tenant = await prisma.tenant.create({ data: input });
        await pythonRagClient.createTenant(tenant);
        return tenant;
      }),

    list: procedure
      .query(async () => {
        return await prisma.tenant.findMany();
      })
  }),

  chat: router({
    create: procedure
      .input(CreateChatRequest)
      .mutation(async ({ input, ctx }) => {
        const chat = await prisma.chat.create({
          data: {
            ...input,
            tenantId: ctx.tenant.id,
            userId: ctx.user.id
          }
        });
        return chat;
      }),

    sendMessage: procedure
      .input(SendMessageRequest)
      .mutation(async ({ input }) => {
        // Store message in TypeScript DB
        const message = await prisma.message.create({
          data: { ...input, role: 'user' }
        });

        // Send to Python RAG for processing
        const ragResponse = await pythonRagClient.query({
          text: input.content,
          language: input.language,
          tenant_id: input.tenantId,
          user_id: input.userId
        });

        // Store AI response
        const aiMessage = await prisma.message.create({
          data: {
            chatId: input.chatId,
            content: ragResponse.answer,
            role: 'assistant',
            metadata: {
              confidence: ragResponse.confidence,
              sources: ragResponse.sources,
              response_time: ragResponse.response_time
            }
          }
        });

        return { userMessage: message, aiMessage };
      })
  })
});

export type AppRouter = typeof appRouter;
```

### 3. Enhanced Python RAG Daemon

```python
from fastapi import FastAPI, WebSocket, BackgroundTasks
from pydantic import BaseModel
import asyncio
import redis.asyncio as redis
from typing import List, Optional
import uvicorn

class RAGServiceDaemon:
    def __init__(self):
        self.app = FastAPI(title="RAG Service Daemon")
        self.redis = None
        self.services = {}
        self.setup_routes()

    async def start(self):
        """Enhanced startup with Redis and real-time capabilities"""
        # Redis for real-time communication with TypeScript layer
        self.redis = redis.Redis.from_url("redis://localhost:6379")

        # Initialize services (from persistent_service_architecture.md)
        self.services = {
            'query': QueryService(self.database_provider),
            'tenant': TenantService(self.database_provider),
            'document': DocumentService(self.database_provider),
            'health': HealthService(self.database_provider)
        }

        # Setup real-time bridge
        await self.setup_realtime_bridge()

    def setup_routes(self):
        """Setup FastAPI routes"""

        @self.app.post("/api/v1/query", response_model=QueryResponse)
        async def process_query(request: QueryRequest):
            """Synchronous query processing"""
            return await self.services['query'].execute_query(request)

        @self.app.post("/api/v1/documents/process")
        async def process_documents(
            request: ProcessDocumentsRequest,
            background_tasks: BackgroundTasks
        ):
            """Asynchronous document processing"""
            task_id = await self.services['document'].process_documents(request)

            # Notify TypeScript layer via Redis
            await self.redis.publish(
                "tasks:started",
                json.dumps({"task_id": task_id, "type": "document_processing"})
            )

            return {"task_id": task_id, "status": "started"}

        @self.app.post("/api/v1/tenants", response_model=TenantResponse)
        async def create_tenant(request: CreateTenantRequest):
            """Tenant creation with RAG setup"""
            return await self.services['tenant'].create_tenant(request)

        @self.app.websocket("/ws")
        async def websocket_endpoint(websocket: WebSocket):
            """Real-time updates for TypeScript clients"""
            await websocket.accept()
            pubsub = self.redis.pubsub()
            await pubsub.subscribe("rag:updates", "tasks:completed", "tasks:progress")

            async for message in pubsub.listen():
                if message['type'] == 'message':
                    await websocket.send_text(message['data'])

    async def setup_realtime_bridge(self):
        """Bridge Python events to TypeScript via Redis"""
        # Background task to publish processing updates
        asyncio.create_task(self._monitor_tasks())

    async def _monitor_tasks(self):
        """Monitor background tasks and publish updates"""
        while True:
            # Check task statuses and publish updates
            tasks = await self.services['document'].get_active_tasks()
            for task in tasks:
                await self.redis.publish(
                    "tasks:progress",
                    json.dumps({
                        "task_id": task.id,
                        "progress": task.progress,
                        "status": task.status
                    })
                )
            await asyncio.sleep(1)
```

### 4. Python Client for TypeScript

```typescript
// python-client.ts
export class PythonRagClient {
  constructor(private baseUrl: string) {}

  async query(request: QueryRequest): Promise<QueryResponse> {
    const response = await fetch(`${this.baseUrl}/api/v1/query`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(request)
    });

    if (!response.ok) {
      throw new Error(`Query failed: ${response.statusText}`);
    }

    return response.json();
  }

  async processDocuments(request: ProcessDocumentsRequest): Promise<string> {
    const response = await fetch(`${this.baseUrl}/api/v1/documents/process`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(request)
    });

    const result = await response.json();
    return result.task_id;
  }

  async getTaskStatus(taskId: string): Promise<TaskStatus> {
    const response = await fetch(`${this.baseUrl}/api/v1/tasks/${taskId}/status`);
    return response.json();
  }

  async createTenant(tenant: CreateTenantRequest): Promise<TenantResponse> {
    const response = await fetch(`${this.baseUrl}/api/v1/tenants`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(tenant)
    });

    return response.json();
  }
}
```

## Architecture Options

### Option 1: Monorepo with Type Generation

```bash
project/
├── apps/
│   ├── api/                    # TypeScript tRPC API
│   │   ├── src/
│   │   │   ├── generated/      # Auto-generated from Python
│   │   │   ├── trpc/          # tRPC routers
│   │   │   ├── lib/           # Python client
│   │   │   └── prisma/        # Database schema
│   │   ├── package.json
│   │   └── prisma/
│   │       └── schema.prisma
│   ├── web/                   # Next.js frontend
│   │   ├── src/
│   │   │   ├── pages/
│   │   │   ├── components/
│   │   │   └── utils/
│   │   └── package.json
│   └── mobile/                # React Native (future)
├── services/
│   └── rag-python/            # Python RAG daemon
│       ├── src/
│       │   ├── api/           # FastAPI endpoints
│       │   ├── services/      # RAG services
│       │   ├── models/        # Pydantic models
│       │   └── utils/
│       ├── generate-types.py  # Generates TS types
│       ├── requirements.txt
│       └── Dockerfile
├── packages/
│   └── shared-types/          # Shared TypeScript types
├── docker-compose.yml
└── README.md
```

**Benefits:**
- Single repository for all code
- Shared type generation pipeline
- Unified development experience
- Easy cross-service changes

### Option 2: Container-First with Event Bridge

```yaml
# docker-compose.yml
version: '3.8'
services:
  typescript-api:
    build: ./typescript-api
    ports: ["3000:3000"]
    environment:
      - PYTHON_RAG_URL=http://python-rag:8080
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://user:pass@postgres:5432/ragdb
    depends_on:
      - python-rag
      - redis
      - postgres

  python-rag:
    build: ./python-rag
    ports: ["8080:8080"]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
    environment:
      - REDIS_URL=redis://redis:6379
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
    depends_on:
      - redis
      - chromadb

  redis:
    image: redis:alpine
    ports: ["6379:6379"]

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=ragdb
      - POSTGRES_USER=raguser
      - POSTGRES_PASSWORD=ragpass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports: ["5432:5432"]

  chromadb:
    image: chromadb/chroma:latest
    ports: ["8000:8000"]
    volumes:
      - chroma_data:/chroma/chroma

volumes:
  postgres_data:
  chroma_data:
```

**Benefits:**
- Independent service scaling
- Production-ready deployment
- Clear service boundaries
- Easy horizontal scaling

### Option 3: Hybrid Event-Driven (RECOMMENDED)

```typescript
// Hybrid approach: TypeScript for user interactions, Python for AI processing

// TypeScript API handles user-facing features
export const userFacingRouter = router({
  // Fast, user-facing operations
  auth: authRouter,              // TypeScript + Prisma
  tenants: tenantRouter,         // TypeScript + Prisma
  chats: chatRouter,             // TypeScript + Prisma + Redis real-time
  users: userRouter,             // TypeScript + Prisma

  // RAG operations proxied to Python with real-time updates
  rag: router({
    query: procedure
      .input(QueryRequestSchema)
      .mutation(async ({ input, ctx }) => {
        // Start async processing in Python
        const taskId = await ragDaemon.startQuery(input);

        // Return immediately with task ID
        return { taskId, status: 'processing' };
      }),

    getQueryResult: procedure
      .input(z.object({ taskId: z.string() }))
      .query(async ({ input }) => {
        // Check if result is ready
        return await ragDaemon.getQueryResult(input.taskId);
      }),

    subscribeToQuery: procedure
      .input(z.object({ taskId: z.string() }))
      .subscription(async function* ({ input }) {
        // Real-time subscription to query progress
        const channel = `query:${input.taskId}`;
        for await (const update of redisSubscription(channel)) {
          yield update;
        }
      })
  })
});
```

```python
# Python daemon handles AI/ML heavy lifting
class RAGDaemon:
    async def start_query(self, request: QueryRequest) -> str:
        """Start async query processing"""
        task_id = str(uuid4())

        # Store task
        await self.redis.setex(
            f"task:{task_id}",
            3600,  # 1 hour TTL
            json.dumps({"status": "processing", "progress": 0})
        )

        # Start background processing
        asyncio.create_task(self._process_query_async(task_id, request))

        return task_id

    async def _process_query_async(self, task_id: str, request: QueryRequest):
        """Background query processing with progress updates"""
        try:
            # Update progress
            await self._update_task_progress(task_id, 10, "Retrieving documents")

            # RAG processing steps
            docs = await self.retriever.get_relevant_docs(request.text)
            await self._update_task_progress(task_id, 50, "Processing with LLM")

            response = await self.llm.generate(request.text, docs)
            await self._update_task_progress(task_id, 90, "Finalizing response")

            # Complete task
            result = QueryResponse(
                answer=response.text,
                confidence=response.confidence,
                sources=[doc.source for doc in docs],
                response_time=time.time() - start_time,
                query_id=task_id
            )

            await self.redis.setex(
                f"task:{task_id}",
                3600,
                json.dumps({
                    "status": "completed",
                    "result": result.model_dump()
                })
            )

            # Publish completion
            await self.redis.publish(
                f"query:{task_id}:completed",
                result.model_dump_json()
            )

        except Exception as e:
            await self._update_task_error(task_id, str(e))

    async def _update_task_progress(self, task_id: str, progress: int, message: str):
        """Update task progress and notify subscribers"""
        update = {"status": "processing", "progress": progress, "message": message}

        await self.redis.setex(f"task:{task_id}", 3600, json.dumps(update))
        await self.redis.publish(f"query:{task_id}:progress", json.dumps(update))
```

## Database Strategy

### Dual Database Approach

```typescript
// Prisma schema for user-facing data
model Tenant {
  id        String   @id @default(cuid())
  name      String
  slug      String   @unique
  settings  Json?
  createdAt DateTime @default(now())

  users User[]
  chats Chat[]
}

model User {
  id       String @id @default(cuid())
  email    String @unique
  tenantId String

  tenant Tenant @relation(fields: [tenantId], references: [id])
  chats  Chat[]
  messages Message[]
}

model Chat {
  id          String   @id @default(cuid())
  title       String
  tenantId    String
  userId      String
  visibility  String   // 'private' | 'tenant_shared'
  ragConfig   Json?
  createdAt   DateTime @default(now())

  tenant   Tenant    @relation(fields: [tenantId], references: [id])
  user     User      @relation(fields: [userId], references: [id])
  messages Message[]
}

model Message {
  id       String   @id @default(cuid())
  chatId   String
  content  String
  role     String   // 'user' | 'assistant'
  metadata Json?    // RAG metadata (sources, confidence, etc.)
  createdAt DateTime @default(now())

  chat Chat @relation(fields: [chatId], references: [id])
}
```

```python
# Python handles RAG-specific data
class TenantService:
    async def create_tenant(self, request: CreateTenantRequest) -> TenantResponse:
        """Create tenant in both systems"""
        # 1. Create in Python RAG system
        tenant_data = {
            "id": request.id,
            "name": request.name,
            "slug": request.slug,
            "rag_config": request.rag_config
        }

        # Setup RAG collections
        await self._setup_tenant_collections(tenant_data)

        # Setup document storage
        await self._create_tenant_folders(tenant_data)

        return TenantResponse(
            id=tenant_data["id"],
            status="active",
            collections_created=True,
            storage_ready=True
        )
```

## Real-Time Features

### WebSocket Integration

```typescript
// TypeScript WebSocket client
export class RAGRealtimeClient {
  private ws: WebSocket | null = null;
  private subscriptions = new Map<string, (data: any) => void>();

  connect() {
    this.ws = new WebSocket('ws://localhost:8080/ws');

    this.ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      const handler = this.subscriptions.get(data.channel);
      if (handler) {
        handler(data.payload);
      }
    };
  }

  subscribeToQuery(taskId: string, callback: (update: any) => void) {
    this.subscriptions.set(`query:${taskId}:progress`, callback);
    this.ws?.send(JSON.stringify({
      action: 'subscribe',
      channel: `query:${taskId}:progress`
    }));
  }

  subscribeToDocumentProcessing(tenantId: string, callback: (update: any) => void) {
    this.subscriptions.set(`documents:${tenantId}:progress`, callback);
    this.ws?.send(JSON.stringify({
      action: 'subscribe',
      channel: `documents:${tenantId}:progress`
    }));
  }
}
```

### tRPC Subscriptions

```typescript
// Real-time tRPC subscriptions
export const realtimeRouter = router({
  queryProgress: procedure
    .input(z.object({ taskId: z.string() }))
    .subscription(async function* ({ input }) {
      const channel = `query:${input.taskId}:progress`;

      for await (const message of redisSubscribe(channel)) {
        yield {
          taskId: input.taskId,
          progress: message.progress,
          status: message.status,
          message: message.message
        };
      }
    }),

  documentProcessing: procedure
    .input(z.object({ tenantId: z.string() }))
    .subscription(async function* ({ input }) {
      const channel = `documents:${input.tenantId}:progress`;

      for await (const message of redisSubscribe(channel)) {
        yield {
          tenantId: input.tenantId,
          documentId: message.documentId,
          progress: message.progress,
          status: message.status
        };
      }
    })
});
```

## Performance Considerations

### Language-Optimized Workloads

**TypeScript Handles:**
- User authentication and authorization
- Real-time chat interfaces
- CRUD operations on user data
- API request/response formatting
- WebSocket management
- Frontend state management

**Python Handles:**
- Vector embeddings generation
- Document processing and chunking
- Similarity search in vector databases
- LLM interactions and prompt engineering
- Complex RAG pipeline orchestration
- ML model inference

### Scaling Strategy

```yaml
# Kubernetes scaling configuration
apiVersion: apps/v1
kind: Deployment
metadata:
  name: typescript-api
spec:
  replicas: 5  # Scale for user load
  template:
    spec:
      containers:
      - name: api
        image: typescript-api:latest
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: python-rag
spec:
  replicas: 3  # Scale for AI processing load
  template:
    spec:
      containers:
      - name: rag
        image: python-rag:latest
        resources:
          requests:
            memory: "2Gi"     # More memory for ML models
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
```

### Caching Strategy

```typescript
// TypeScript caching
export class CacheService {
  constructor(private redis: Redis) {}

  async getCachedQuery(queryHash: string): Promise<QueryResponse | null> {
    const cached = await this.redis.get(`query:${queryHash}`);
    return cached ? JSON.parse(cached) : null;
  }

  async cacheQuery(queryHash: string, response: QueryResponse, ttl: number = 3600) {
    await this.redis.setex(`query:${queryHash}`, ttl, JSON.stringify(response));
  }
}
```

```python
# Python caching
class QueryService:
    async def execute_query(self, request: QueryRequest) -> QueryResponse:
        # Check cache first
        query_hash = self._hash_query(request)
        cached = await self.redis.get(f"query_result:{query_hash}")

        if cached:
            return QueryResponse.model_validate_json(cached)

        # Process query
        result = await self._process_rag_pipeline(request)

        # Cache result
        await self.redis.setex(
            f"query_result:{query_hash}",
            3600,  # 1 hour
            result.model_dump_json()
        )

        return result
```

## Development Workflow

### Type Generation Pipeline

```bash
# generate-types.sh
#!/bin/bash

echo "Generating TypeScript types from Python models..."

# Generate types from Pydantic models
cd services/rag-python
python -m pydantic-to-typescript \
  --module src.models.api_models \
  --output ../../apps/api/src/generated/python-types.ts \
  --json2ts-cmd "npx json2ts"

# Format generated types
cd ../../apps/api
npx prettier --write src/generated/python-types.ts

echo "Types generated successfully!"
```

### Development Commands

```json
{
  "scripts": {
    "dev": "concurrently \"npm run dev:python\" \"npm run dev:typescript\"",
    "dev:python": "cd services/rag-python && uvicorn src.main:app --reload --port 8080",
    "dev:typescript": "cd apps/api && npm run dev",
    "generate:types": "./scripts/generate-types.sh",
    "test": "npm run test:python && npm run test:typescript",
    "test:python": "cd services/rag-python && pytest",
    "test:typescript": "cd apps/api && npm run test",
    "build": "npm run build:python && npm run build:typescript",
    "deploy": "docker-compose up --build"
  }
}
```

### Hot Reload Configuration

```python
# Python hot reload with type generation
import asyncio
from watchfiles import awatch

async def watch_models():
    """Watch for model changes and regenerate types"""
    async for changes in awatch('src/models/'):
        print("Models changed, regenerating TypeScript types...")
        subprocess.run(['./scripts/generate-types.sh'])

# Start watcher in development
if __name__ == "__main__":
    if os.getenv("ENVIRONMENT") == "development":
        asyncio.create_task(watch_models())
```

## Security Considerations

### Authentication Flow

```typescript
// JWT token validation across services
export const authMiddleware = async (req: Request, res: Response, next: NextFunction) => {
  const token = req.headers.authorization?.replace('Bearer ', '');

  if (!token) {
    return res.status(401).json({ error: 'No token provided' });
  }

  try {
    const decoded = jwt.verify(token, process.env.JWT_SECRET!) as JWTPayload;

    // Add user context for Python service calls
    req.user = decoded;
    req.headers['x-user-id'] = decoded.userId;
    req.headers['x-tenant-id'] = decoded.tenantId;

    next();
  } catch (error) {
    return res.status(401).json({ error: 'Invalid token' });
  }
};
```

```python
# Python service authentication
from fastapi import HTTPException, Depends
from fastapi.security import HTTPBearer

security = HTTPBearer()

async def get_current_user(token: str = Depends(security)) -> UserContext:
    """Extract user context from JWT token"""
    try:
        payload = jwt.decode(token.credentials, settings.JWT_SECRET, algorithms=["HS256"])
        return UserContext(
            user_id=payload["userId"],
            tenant_id=payload["tenantId"],
            permissions=payload["permissions"]
        )
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="Invalid token")

@app.post("/api/v1/query")
async def process_query(
    request: QueryRequest,
    user: UserContext = Depends(get_current_user)
):
    """Query endpoint with user context"""
    # Add user context to request
    request.user_id = user.user_id
    request.tenant_id = user.tenant_id

    return await query_service.execute_query(request)
```

### Data Isolation

```python
# Row-level security in Python
class TenantAwareService:
    def __init__(self, database_provider: DatabaseProvider):
        self.db = database_provider

    async def ensure_tenant_access(self, user_context: UserContext, tenant_id: str):
        """Ensure user has access to tenant"""
        if user_context.tenant_id != tenant_id:
            raise HTTPException(
                status_code=403,
                detail="Access denied: User not in tenant"
            )

    async def get_tenant_documents(self, user_context: UserContext) -> List[Document]:
        """Get documents with automatic tenant filtering"""
        await self.ensure_tenant_access(user_context, user_context.tenant_id)

        return await self.db.get_documents(
            filters={"tenant_id": user_context.tenant_id}
        )
```

## Implementation Roadmap

### Phase 1: Foundation Setup (Week 1-2)
1. **Project Structure**
   - Setup monorepo with TypeScript and Python services
   - Configure Docker development environment
   - Setup basic CI/CD pipeline

2. **Type Generation**
   - Implement pydantic-to-typescript pipeline
   - Create basic Python models for API
   - Test type generation and validation

3. **Basic Services**
   - Python FastAPI server with health endpoints
   - TypeScript tRPC router with basic endpoints
   - Redis setup for inter-service communication

### Phase 2: Core Integration (Week 3-4)
1. **Database Setup**
   - PostgreSQL with Prisma for TypeScript data
   - Python RAG service with vector storage
   - Implement dual-database strategy

2. **Authentication**
   - JWT authentication across both services
   - User context propagation
   - Basic security middleware

3. **Basic RAG Pipeline**
   - Simple query processing in Python
   - TypeScript API integration
   - Real-time progress updates via Redis

### Phase 3: Advanced Features (Week 5-6)
1. **Multi-tenancy**
   - Tenant management across both services
   - Data isolation and row-level security
   - Tenant-specific RAG configurations

2. **Real-time Features**
   - WebSocket connections for live updates
   - tRPC subscriptions for query progress
   - Document processing status updates

3. **Chat Interface**
   - Chat management in TypeScript
   - Message storage and retrieval
   - Integration with RAG processing

### Phase 4: Production Ready (Week 7-8)
1. **Performance Optimization**
   - Caching strategies
   - Database query optimization
   - Service scaling configuration

2. **Monitoring & Observability**
   - Logging across both services
   - Metrics collection and dashboards
   - Health checks and alerting

3. **Deployment**
   - Production Docker configurations
   - Kubernetes deployment manifests
   - CI/CD automation

### Phase 5: Advanced Features (Week 9+)
1. **Document Management**
   - File upload and processing
   - Document version control
   - Metadata extraction and indexing

2. **Analytics**
   - Query analytics and insights
   - Usage metrics and reporting
   - Performance monitoring

3. **API Extensions**
   - Advanced search capabilities
   - Bulk operations
   - Import/export functionality

## Benefits Summary

### Technical Benefits
1. **Type Safety** - End-to-end type safety with automatic generation
2. **Performance** - Language-optimized workloads (TS for I/O, Python for AI/ML)
3. **Scalability** - Independent scaling of user and AI processing loads
4. **Maintainability** - Clear separation of concerns and well-defined interfaces

### Development Benefits
1. **AI-Friendly** - Clear interfaces and auto-generation make it ideal for AI development
2. **Modern Stack** - Leverages 2024's best practices in both ecosystems
3. **Developer Experience** - Hot reload, type checking, and excellent tooling
4. **Future Proof** - Modular architecture allows easy technology swapping

### Business Benefits
1. **Faster Development** - Reduced boilerplate and clear patterns
2. **Lower Maintenance** - Type safety catches errors early
3. **Better Performance** - Optimized for both user experience and AI processing
4. **Easier Scaling** - Independent service scaling reduces infrastructure costs

## Conclusion

This architecture provides a modern, scalable, and type-safe foundation for building RAG systems that leverage the strengths of both TypeScript and Python ecosystems. The dual-layer approach with automatic type generation ensures consistency while allowing each language to handle what it does best.

The hybrid event-driven pattern (Option 3) is recommended for most use cases as it provides the best balance of performance, scalability, and developer experience while being optimized for AI code generation.

## Next Steps

1. **Prototype Development** - Build a minimal working version to validate the architecture
2. **Performance Testing** - Benchmark the type generation and inter-service communication
3. **Security Review** - Validate authentication and data isolation strategies
4. **Documentation** - Create detailed implementation guides and API documentation
5. **Team Training** - Ensure development team is familiar with both TypeScript and Python patterns

---

*This document will be updated as implementation progresses and new insights are discovered.*
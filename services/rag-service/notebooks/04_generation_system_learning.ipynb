{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Multilingual Generation System Learning\n",
    "## Local LLM Integration with Qwen2.5 for Multilingual RAG\n",
    "\n",
    "This notebook explores Step 4 of our **Multilingual RAG system** - the **Generation System** using Qwen2.5 for local multilingual LLM processing. We'll learn how to integrate multilingual language models, create language-specific prompts, and handle cross-language generation.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand local multilingual LLM integration benefits and challenges\n",
    "- Learn language-specific prompt engineering (Croatian, English)\n",
    "- Implement multilingual response parsing and quality assessment\n",
    "- Explore cross-language generation strategies for various query types\n",
    "- Test the complete multilingual generation pipeline\n",
    "\n",
    "### Current Multilingual Implementation\n",
    "üåç **Model**: qwen2.5:7b-instruct - Full multilingual support  \n",
    "üá≠üá∑ **Croatian**: Excellent output with proper diacritics and cultural context  \n",
    "üá¨üáß **English**: Professional business and technical response generation  \n",
    "üîÑ **Cross-Language**: Croatian queries with English context, and vice versa  \n",
    "‚ö° **Performance**: Optimized for multilingual processing  \n",
    "üéØ **Language Routing**: Automatic language detection and appropriate response formatting\n",
    "\n",
    "### Multilingual Generation Capabilities\n",
    "- **üá≠üá∑ Croatian Responses**: Cultural context, proper grammar, diacritics\n",
    "- **üá¨üáß English Responses**: Business format, technical precision\n",
    "- **üåê Cross-Language**: Query in one language, respond in user's preferred language  \n",
    "- **üîç Source Attribution**: Multilingual source citation and metadata\n",
    "- **üìä Quality Control**: Language-specific response validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.generation.ollama_client import (\n",
    "    OllamaClient, OllamaConfig, GenerationRequest,\n",
    "    GenerationResponse, create_ollama_client\n",
    ")\n",
    "from src.generation.prompt_templates import (\n",
    "    CroatianRAGPrompts, PromptBuilder,\n",
    "    get_prompt_for_query_type, create_prompt_builder\n",
    ")\n",
    "from src.generation.response_parser import (\n",
    "    CroatianResponseParser, ParsedResponse, create_response_parser\n",
    ")\n",
    "\n",
    "# Set up display options\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Generation system imports successful\")\n",
    "print(\"üöÄ Current optimized model: qwen2.5:7b-instruct\")\n",
    "print(\"‚ö° Performance improvement: 32% faster generation\")\n",
    "print(\"üá≠üá∑ Croatian language quality: Excellent with proper diacritics\")\n",
    "print(\"üìä Avg generation time: 83.5s (optimized from 123s baseline)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Local LLM Generation\n",
    "\n",
    "### Why Local LLMs for Croatian RAG?\n",
    "\n",
    "**Privacy & Control**:\n",
    "- Documents never leave your machine\n",
    "- No data sent to external APIs\n",
    "- Full control over model behavior\n",
    "\n",
    "**Cost Efficiency**:\n",
    "- No per-query API costs\n",
    "- Unlimited usage after setup\n",
    "- Predictable resource usage\n",
    "\n",
    "**Croatian Language Support**:\n",
    "- Modern models handle Croatian well\n",
    "- Can fine-tune for specific domains\n",
    "- Custom prompt engineering for cultural context\n",
    "\n",
    "### Challenges with Local Generation\n",
    "\n",
    "- **Hardware Requirements**: Need sufficient RAM and compute\n",
    "- **Model Selection**: Choosing the right model for Croatian\n",
    "- **Quality Control**: Ensuring consistent, high-quality outputs\n",
    "- **Speed vs Quality**: Balancing response time with answer quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize local LLM generation architecture\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 10))\n",
    "\n",
    "# Components and their positions\n",
    "components = {\n",
    "    'Query Processor': (1, 8),\n",
    "    'Retrieval System': (1, 6),\n",
    "    'Context Chunks': (3, 6),\n",
    "    'Prompt Templates': (5, 8),\n",
    "    'Prompt Builder': (7, 8),\n",
    "    'Ollama LLM': (9, 6),\n",
    "    'Response Parser': (11, 6),\n",
    "    'Final Answer': (13, 6)\n",
    "}\n",
    "\n",
    "# Draw components\n",
    "for name, (x, y) in components.items():\n",
    "    if name == 'Ollama LLM':\n",
    "        # Highlight the LLM as the core component\n",
    "        rect = plt.Rectangle((x-0.8, y-0.4), 1.6, 0.8,\n",
    "                           facecolor='lightcoral', edgecolor='red', linewidth=2)\n",
    "    elif name in ['Prompt Templates', 'Prompt Builder', 'Response Parser']:\n",
    "        # Highlight generation-specific components\n",
    "        rect = plt.Rectangle((x-0.8, y-0.4), 1.6, 0.8,\n",
    "                           facecolor='lightblue', edgecolor='blue', linewidth=2)\n",
    "    else:\n",
    "        rect = plt.Rectangle((x-0.8, y-0.4), 1.6, 0.8,\n",
    "                           facecolor='lightgray', edgecolor='black')\n",
    "\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, y, name, ha='center', va='center', fontsize=9, weight='bold')\n",
    "\n",
    "# Draw data flow arrows\n",
    "arrows = [\n",
    "    ((1.8, 8), (4.2, 8)),      # Query ‚Üí Templates\n",
    "    ((1.8, 6), (2.2, 6)),      # Retrieval ‚Üí Context\n",
    "    ((3.8, 6), (6.2, 7.5)),    # Context ‚Üí Prompt Builder\n",
    "    ((5.8, 8), (6.2, 8)),      # Templates ‚Üí Builder\n",
    "    ((7.8, 8), (8.2, 6.5)),    # Builder ‚Üí LLM\n",
    "    ((9.8, 6), (10.2, 6)),     # LLM ‚Üí Parser\n",
    "    ((11.8, 6), (12.2, 6))     # Parser ‚Üí Answer\n",
    "]\n",
    "\n",
    "for (x1, y1), (x2, y2) in arrows:\n",
    "    ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
    "                arrowprops=dict(arrowstyle='->', lw=2, color='darkgreen'))\n",
    "\n",
    "# Add Croatian-specific annotations\n",
    "croatian_features = [\n",
    "    (5, 9, \"Croatian Query\\nType Detection\"),\n",
    "    (7, 9, \"Cultural Context\\nIntegration\"),\n",
    "    (9, 4.5, \"Diacritic\\nPreservation\"),\n",
    "    (11, 4.5, \"Croatian Language\\nQuality Check\")\n",
    "]\n",
    "\n",
    "for x, y, text in croatian_features:\n",
    "    ax.text(x, y, text, ha='center', va='center', fontsize=8,\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightyellow', alpha=0.7))\n",
    "\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(3, 10)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title('Croatian RAG Generation System Architecture\\n(Step 4: Local LLM Integration)',\n",
    "            fontsize=14, weight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Generation system architecture visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ollama Client Configuration\n",
    "\n",
    "Let's explore the Ollama client and its Croatian-specific configuration options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure Ollama client\n",
    "config = OllamaConfig(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0.7,           # Balanced creativity vs consistency\n",
    "    max_tokens=2000,          # Sufficient for detailed Croatian responses\n",
    "    preserve_diacritics=True, # Essential for Croatian\n",
    "    prefer_formal_style=True, # Professional Croatian language\n",
    "    include_cultural_context=True  # Croatian cultural awareness\n",
    ")\n",
    "\n",
    "client = OllamaClient(config)\n",
    "\n",
    "print(\"üîß Ollama Client Configuration:\")\n",
    "print(f\"Model: {config.model}\")\n",
    "print(f\"Temperature: {config.temperature}\")\n",
    "print(f\"Max Tokens: {config.max_tokens}\")\n",
    "print(f\"Preserve Diacritics: {config.preserve_diacritics}\")\n",
    "print(f\"Formal Style: {config.prefer_formal_style}\")\n",
    "print(f\"Cultural Context: {config.include_cultural_context}\")\n",
    "\n",
    "# Check if Ollama service is running\n",
    "is_healthy = client.health_check()\n",
    "print(f\"\\nüè• Ollama Service Status: {'‚úÖ Running' if is_healthy else '‚ùå Not Available'}\")\n",
    "\n",
    "if is_healthy:\n",
    "    available_models = client.get_available_models()\n",
    "    print(f\"üì¶ Available Models: {available_models}\")\n",
    "\n",
    "    if config.model in available_models:\n",
    "        print(f\"‚úÖ Model {config.model} is ready\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Model {config.model} needs to be pulled\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  To start Ollama: ollama serve\")\n",
    "    print(\"‚ÑπÔ∏è  To pull model: ollama pull llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Croatian Prompt Engineering\n",
    "\n",
    "Effective prompt engineering is crucial for high-quality Croatian generation. Let's explore our template system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore different Croatian prompt templates\n",
    "template_examples = {\n",
    "    \"General Q&A\": CroatianRAGPrompts.QUESTION_ANSWERING,\n",
    "    \"Factual Questions\": CroatianRAGPrompts.FACTUAL_QA,\n",
    "    \"Explanatory\": CroatianRAGPrompts.EXPLANATORY,\n",
    "    \"Cultural Context\": CroatianRAGPrompts.CULTURAL_CONTEXT,\n",
    "    \"Tourism\": CroatianRAGPrompts.TOURISM,\n",
    "    \"Summarization\": CroatianRAGPrompts.SUMMARIZATION,\n",
    "    \"Comparison\": CroatianRAGPrompts.COMPARISON\n",
    "}\n",
    "\n",
    "print(\"üéØ Croatian Prompt Templates Overview:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, template in template_examples.items():\n",
    "    print(f\"\\nüìã {name} Template:\")\n",
    "\n",
    "    # Show first 150 characters of system prompt\n",
    "    system_preview = template.system_prompt[:150] + \"...\" if len(template.system_prompt) > 150 else template.system_prompt\n",
    "    print(f\"System: {system_preview}\")\n",
    "\n",
    "    # Show user template\n",
    "    print(f\"User: {template.user_template}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test automatic template selection for Croatian queries\n",
    "test_queries = {\n",
    "    \"Koji je glavni grad Hrvatske?\": \"Should select FACTUAL_QA\",\n",
    "    \"Objasni hrvatsku kulturu\": \"Should select CULTURAL_CONTEXT or EXPLANATORY\",\n",
    "    \"Najbolja mjesta za turizam u Istri\": \"Should select TOURISM\",\n",
    "    \"Sa≈æmi povijest Dubrovnika\": \"Should select SUMMARIZATION\",\n",
    "    \"Usporedi Zagreb i Split\": \"Should select COMPARISON\",\n",
    "    \"Kako nastaju Plitviƒçka jezera?\": \"Should select EXPLANATORY\",\n",
    "    \"≈†to je biser Jadrana?\": \"Should select CULTURAL_CONTEXT\"\n",
    "}\n",
    "\n",
    "print(\"ü§ñ Automatic Template Selection Test:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "template_names = {\n",
    "    CroatianRAGPrompts.FACTUAL_QA: \"FACTUAL_QA\",\n",
    "    CroatianRAGPrompts.EXPLANATORY: \"EXPLANATORY\",\n",
    "    CroatianRAGPrompts.CULTURAL_CONTEXT: \"CULTURAL_CONTEXT\",\n",
    "    CroatianRAGPrompts.TOURISM: \"TOURISM\",\n",
    "    CroatianRAGPrompts.SUMMARIZATION: \"SUMMARIZATION\",\n",
    "    CroatianRAGPrompts.COMPARISON: \"COMPARISON\",\n",
    "    CroatianRAGPrompts.QUESTION_ANSWERING: \"QUESTION_ANSWERING\"\n",
    "}\n",
    "\n",
    "for query, expected in test_queries.items():\n",
    "    selected_template = get_prompt_for_query_type(query)\n",
    "    template_name = template_names.get(selected_template, \"UNKNOWN\")\n",
    "\n",
    "    print(f\"\\nüìù Query: {query}\")\n",
    "    print(f\"üéØ Selected: {template_name}\")\n",
    "    print(f\"üí≠ Expected: {expected}\")\n",
    "\n",
    "    # Check if selection makes sense\n",
    "    if any(keyword in expected for keyword in [template_name]):\n",
    "        print(\"‚úÖ Good selection\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Check selection logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompt Building and Context Integration\n",
    "\n",
    "Let's see how prompts are built with context chunks and Croatian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Croatian context chunks\n",
    "croatian_context = [\n",
    "    \"Zagreb je glavni i najveƒái grad Republike Hrvatske. Smje≈°ten je na\"\n",
    "    \" sjeverozapadu zemlje, uz rijeku Savu. Zagreb ima oko 800.000 stanovnika\"\n",
    "    \" u gradskim granicama i preko 1.1 milijuna u ≈°iroj gradskoj oblasti.\",\n",
    "\n",
    "    \"Dubrovnik je grad u Dubrovaƒçko-neretvanskoj ≈æupaniji u Hrvatskoj\"\n",
    "    \" Dalmaciji. Poznat je kao 'biser Jadrana' zbog svoje izuzetne ljepote\"\n",
    "    \" i bogate povijesti. Dubrovnik je upisan na UNESCO-ov popis svjetske ba≈°tine.\",\n",
    "\n",
    "    \"Plitviƒçka jezera su nacionalni park u Hrvatskoj gorskoj regiji Lika.\"\n",
    "    \" Park je poznat po nizovima terasa od ≈°esnaest jezera povezanih\"\n",
    "    \" slapovima i kaskadama. Takoƒëer je UNESCO-ova svjetska ba≈°tina.\"\n",
    "]\n",
    "\n",
    "# Test different query types with context\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"Koji je glavni grad Hrvatske?\",\n",
    "        \"type\": \"factual\",\n",
    "        \"context\": croatian_context[:1]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Objasni za≈°to je Dubrovnik poznat?\",\n",
    "        \"type\": \"cultural\",\n",
    "        \"context\": croatian_context[1:2]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Usporedi Zagreb i Dubrovnik\",\n",
    "        \"type\": \"comparison\",\n",
    "        \"context\": croatian_context[:2]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üî® Prompt Building Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    query = case[\"query\"]\n",
    "    context = case[\"context\"]\n",
    "\n",
    "    # Build prompt\n",
    "    builder = create_prompt_builder(query)\n",
    "    system_prompt, user_prompt = builder.build_prompt(query, context)\n",
    "\n",
    "    print(f\"\\nüìù Example {i}: {case['type'].title()} Query\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"\\nüõ†Ô∏è  System Prompt (first 200 chars):\")\n",
    "    print(system_prompt[:200] + \"...\")\n",
    "\n",
    "    print(f\"\\nüë§ User Prompt:\")\n",
    "    print(user_prompt)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generation Testing\n",
    "\n",
    "Let's test the actual generation with our Croatian context (requires Ollama to be running)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generation with Croatian content\n",
    "async def test_croatian_generation():\n",
    "    \"\"\"Test Croatian text generation.\"\"\"\n",
    "    if not client.health_check():\n",
    "        print(\"‚ùå Ollama service not available. Please start with: ollama serve\")\n",
    "        return\n",
    "\n",
    "    # Test queries with different complexity\n",
    "    test_requests = [\n",
    "        {\n",
    "            \"query\": \"≈†to je Zagreb?\",\n",
    "            \"context\": [croatian_context[0]],\n",
    "            \"type\": \"factual\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Za≈°to se Dubrovnik naziva 'biser Jadrana'?\",\n",
    "            \"context\": [croatian_context[1]],\n",
    "            \"type\": \"cultural\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Objasni znaƒçaj Plitviƒçkih jezera\",\n",
    "            \"context\": [croatian_context[2]],\n",
    "            \"type\": \"explanatory\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    print(\"üöÄ Testing Croatian Generation:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for i, test_case in enumerate(test_requests, 1):\n",
    "        print(f\"\\nüîÑ Test {i}: {test_case['type'].title()} Query\")\n",
    "        print(f\"Query: {test_case['query']}\")\n",
    "\n",
    "        # Build the request\n",
    "        builder = create_prompt_builder(test_case[\"query\"])\n",
    "        system_prompt, user_prompt = builder.build_prompt(\n",
    "            test_case[\"query\"],\n",
    "            test_case[\"context\"]\n",
    "        )\n",
    "\n",
    "        request = GenerationRequest(\n",
    "            prompt=user_prompt,\n",
    "            context=test_case[\"context\"],\n",
    "            query=test_case[\"query\"],\n",
    "            query_type=test_case[\"type\"],\n",
    "            language=\"hr\"\n",
    "        )\n",
    "\n",
    "        # Generate response\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            async with OllamaClient(config) as async_client:\n",
    "                response = await async_client.generate_text_async(request)\n",
    "\n",
    "                generation_time = time.time() - start_time\n",
    "\n",
    "                print(f\"‚è±Ô∏è  Generation Time: {generation_time:.2f}s\")\n",
    "                print(f\"üéØ Confidence: {response.confidence:.3f}\")\n",
    "                print(f\"üìä Tokens Used: {response.tokens_used}\")\n",
    "                print(f\"\\nüí¨ Response:\")\n",
    "                print(response.text)\n",
    "\n",
    "                # Check for Croatian content\n",
    "                if response.has_croatian_content:\n",
    "                    print(\"‚úÖ Contains Croatian content\")\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è  Low Croatian content detected\")\n",
    "\n",
    "                results.append({\n",
    "                    'query': test_case['query'],\n",
    "                    'response': response.text,\n",
    "                    'confidence': response.confidence,\n",
    "                    'generation_time': generation_time,\n",
    "                    'tokens': response.tokens_used,\n",
    "                    'croatian_content': response.has_croatian_content\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            results.append({\n",
    "                'query': test_case['query'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run the test\n",
    "generation_results = await test_croatian_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Response Parsing and Quality Assessment\n",
    "\n",
    "Let's explore how we parse and assess the quality of generated Croatian responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test response parsing with various Croatian responses\n",
    "parser = create_response_parser()\n",
    "\n",
    "# Sample responses for testing\n",
    "test_responses = {\n",
    "    \"High Quality\": \"Zagreb je glavni i najveƒái grad Republike Hrvatske, smje≈°ten na sjeverozapadu zemlje uz rijeku Savu. Grad ima bogatu povijest i kulturnu ba≈°tinu, te je va≈æno politiƒçko, gospodarsko i kulturno sredi≈°te zemlje.\",\n",
    "\n",
    "    \"Medium Quality\": \"Zagreb je glavni grad. Mo≈æda ima oko 800 tisuƒáa stanovnika, ƒçini se da je va≈æan grad u Hrvatskoj.\",\n",
    "\n",
    "    \"Low Quality\": \"Ne znam toƒçno ≈°to je Zagreb, nema dovoljno informacija u dostupnim dokumentima.\",\n",
    "\n",
    "    \"With Sources\": \"Zagreb je glavni grad Hrvatske [Dokument 1]. Prema dokumentu, grad ima oko 800.000 stanovnika i smje≈°ten je uz rijeku Savu.\",\n",
    "\n",
    "    \"Mixed Language\": \"Zagreb is the capital city, ali takoƒëer je i najveƒái grad u hrvatskoj.\"\n",
    "}\n",
    "\n",
    "print(\"üîç Response Parsing Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "parsing_results = []\n",
    "\n",
    "for category, response_text in test_responses.items():\n",
    "    parsed = parser.parse_response(\n",
    "        response_text,\n",
    "        query=\"≈†to je Zagreb?\",\n",
    "        context_chunks=[\"Zagreb context...\"]\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìù {category} Response:\")\n",
    "    print(f\"Text: {response_text[:100]}...\")\n",
    "    print(f\"üéØ Confidence: {parsed.confidence:.3f}\")\n",
    "    print(f\"üè≥Ô∏è  Language: {parsed.language}\")\n",
    "    print(f\"‚úÖ Has Answer: {parsed.has_answer}\")\n",
    "    print(f\"üìö Sources: {len(parsed.sources_mentioned)}\")\n",
    "\n",
    "    if parsed.sources_mentioned:\n",
    "        print(f\"   Sources: {parsed.sources_mentioned}\")\n",
    "\n",
    "    parsing_results.append({\n",
    "        'category': category,\n",
    "        'confidence': parsed.confidence,\n",
    "        'language': parsed.language,\n",
    "        'has_answer': parsed.has_answer,\n",
    "        'sources_count': len(parsed.sources_mentioned)\n",
    "    })\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Visualize parsing results\n",
    "categories = [r['category'] for r in parsing_results]\n",
    "confidences = [r['confidence'] for r in parsing_results]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Confidence scores\n",
    "bars = ax1.bar(categories, confidences, color=['green', 'orange', 'red', 'blue', 'purple'])\n",
    "ax1.set_title('Response Quality Assessment\\n(Confidence Scores)', weight='bold')\n",
    "ax1.set_ylabel('Confidence Score')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, conf in zip(bars, confidences):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "             f'{conf:.3f}', ha='center', va='bottom', weight='bold')\n",
    "\n",
    "# Language distribution\n",
    "languages = [r['language'] for r in parsing_results]\n",
    "lang_counts = {lang: languages.count(lang) for lang in set(languages)}\n",
    "\n",
    "ax2.pie(lang_counts.values(), labels=lang_counts.keys(), autopct='%1.1f%%',\n",
    "        colors=['lightblue', 'lightcoral', 'lightgray'])\n",
    "ax2.set_title('Language Detection Results', weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Response parsing analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generation Performance Analysis\n",
    "\n",
    "Let's analyze the performance characteristics of our generation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze generation results if we have them\n",
    "if generation_results and not any('error' in result for result in generation_results):\n",
    "    print(\"üìà Generation Performance Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Extract metrics\n",
    "    queries = [r['query'] for r in generation_results]\n",
    "    confidences = [r['confidence'] for r in generation_results]\n",
    "    times = [r['generation_time'] for r in generation_results]\n",
    "    tokens = [r['tokens'] for r in generation_results]\n",
    "    croatian_content = [r['croatian_content'] for r in generation_results]\n",
    "\n",
    "    # Performance statistics\n",
    "    avg_confidence = np.mean(confidences)\n",
    "    avg_time = np.mean(times)\n",
    "    avg_tokens = np.mean(tokens)\n",
    "    croatian_percentage = (sum(croatian_content) / len(croatian_content)) * 100\n",
    "\n",
    "    print(f\"\\nüìä Performance Metrics:\")\n",
    "    print(f\"Average Confidence: {avg_confidence:.3f}\")\n",
    "    print(f\"Average Generation Time: {avg_time:.2f}s\")\n",
    "    print(f\"Average Tokens Generated: {avg_tokens:.0f}\")\n",
    "    print(f\"Croatian Content Rate: {croatian_percentage:.1f}%\")\n",
    "    print(f\"Tokens per Second: {avg_tokens/avg_time:.1f}\")\n",
    "\n",
    "    # Visualize performance\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # Confidence by query\n",
    "    bars1 = ax1.bar(range(len(queries)), confidences, color='lightblue')\n",
    "    ax1.set_title('Confidence by Query', weight='bold')\n",
    "    ax1.set_ylabel('Confidence Score')\n",
    "    ax1.set_xticks(range(len(queries)))\n",
    "    ax1.set_xticklabels([f'Q{i+1}' for i in range(len(queries))])\n",
    "    ax1.set_ylim(0, 1)\n",
    "\n",
    "    for bar, conf in zip(bars1, confidences):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                 f'{conf:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    # Generation time by query\n",
    "    bars2 = ax2.bar(range(len(queries)), times, color='lightcoral')\n",
    "    ax2.set_title('Generation Time by Query', weight='bold')\n",
    "    ax2.set_ylabel('Time (seconds)')\n",
    "    ax2.set_xticks(range(len(queries)))\n",
    "    ax2.set_xticklabels([f'Q{i+1}' for i in range(len(queries))])\n",
    "\n",
    "    for bar, time_val in zip(bars2, times):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                 f'{time_val:.1f}s', ha='center', va='bottom')\n",
    "\n",
    "    # Tokens generated\n",
    "    bars3 = ax3.bar(range(len(queries)), tokens, color='lightgreen')\n",
    "    ax3.set_title('Tokens Generated by Query', weight='bold')\n",
    "    ax3.set_ylabel('Token Count')\n",
    "    ax3.set_xticks(range(len(queries)))\n",
    "    ax3.set_xticklabels([f'Q{i+1}' for i in range(len(queries))])\n",
    "\n",
    "    for bar, token_count in zip(bars3, tokens):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n",
    "                 f'{token_count}', ha='center', va='bottom')\n",
    "\n",
    "    # Croatian content detection\n",
    "    croatian_labels = ['Croatian Content', 'Non-Croatian']\n",
    "    croatian_counts = [sum(croatian_content), len(croatian_content) - sum(croatian_content)]\n",
    "    ax4.pie(croatian_counts, labels=croatian_labels, autopct='%1.1f%%',\n",
    "            colors=['lightblue', 'lightgray'])\n",
    "    ax4.set_title('Croatian Content Detection', weight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No generation results available for analysis.\")\n",
    "    print(\"   Either Ollama is not running or there were errors during generation.\")\n",
    "    print(\"\\nüìä Simulated Performance Metrics (Example):\")\n",
    "\n",
    "    # Show example metrics\n",
    "    simulated_metrics = {\n",
    "        \"Average Confidence\": 0.756,\n",
    "        \"Average Generation Time\": 2.3,\n",
    "        \"Average Tokens Generated\": 127,\n",
    "        \"Croatian Content Rate\": 92.3,\n",
    "        \"Tokens per Second\": 55.2\n",
    "    }\n",
    "\n",
    "    for metric, value in simulated_metrics.items():\n",
    "        if \"Time\" in metric:\n",
    "            print(f\"{metric}: {value}s\")\n",
    "        elif \"Rate\" in metric or \"per Second\" in metric:\n",
    "            print(f\"{metric}: {value}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Enhanced Multilingual Examples & Language Detection\n",
    "\n",
    "### üåç Comprehensive Language Detection Demo\n",
    "\n",
    "This section demonstrates advanced language detection capabilities with real-world multilingual examples including Croatian, English, and mixed-language content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced multilingual text examples for language detection\n",
    "multilingual_test_cases = {\n",
    "    \"üá≠üá∑ Croatian Business\": {\n",
    "        \"text\": \"Odluka Vlade Republike Hrvatske o izmjeni Zakona o radu stupila je na snagu 1. srpnja 2025. Novi propisi ukljuƒçuju poveƒáanje minimalne plaƒáe na 721,79 EUR mjeseƒçno.\",\n",
    "        \"expected_language\": \"hr\",\n",
    "        \"category\": \"legal_business\",\n",
    "        \"complexity\": \"formal_administrative\"\n",
    "    },\n",
    "\n",
    "    \"üá≠üá∑ Croatian Technical\": {\n",
    "        \"text\": \"Implementacija algoritma za pretra≈æivanje kroz vektorsku bazu podataka koristi BGE-M3 embeddings s dimenzijom od 1024 vektora.\",\n",
    "        \"expected_language\": \"hr\",\n",
    "        \"category\": \"technical\",\n",
    "        \"complexity\": \"technical_terminology\"\n",
    "    },\n",
    "\n",
    "    \"üá≠üá∑ Croatian Informal\": {\n",
    "        \"text\": \"Molim vas, mo≈æete li mi objasniti kako funkcionira ovaj sustav? ƒåini mi se priliƒçno komplicirano za kori≈°tenje.\",\n",
    "        \"expected_language\": \"hr\",\n",
    "        \"category\": \"conversational\",\n",
    "        \"complexity\": \"everyday_informal\"\n",
    "    },\n",
    "\n",
    "    \"üá¨üáß English Business\": {\n",
    "        \"text\": \"The quarterly revenue report shows an increase of 15.3% year-over-year, reaching ‚Ç¨2.4 million in Q3 2025.\",\n",
    "        \"expected_language\": \"en\",\n",
    "        \"category\": \"business_financial\",\n",
    "        \"complexity\": \"professional_formal\"\n",
    "    },\n",
    "\n",
    "    \"üá¨üáß English Technical\": {\n",
    "        \"text\": \"The RAG system utilizes hybrid retrieval combining dense BGE-M3 embeddings with sparse BM25 indexing for optimal performance.\",\n",
    "        \"expected_language\": \"en\",\n",
    "        \"category\": \"technical\",\n",
    "        \"complexity\": \"technical_jargon\"\n",
    "    },\n",
    "\n",
    "    \"üá¨üáß English Conversational\": {\n",
    "        \"text\": \"Could you please help me understand how this document processing pipeline works? I'm trying to implement it for my project.\",\n",
    "        \"expected_language\": \"en\",\n",
    "        \"category\": \"conversational\",\n",
    "        \"complexity\": \"everyday_polite\"\n",
    "    },\n",
    "\n",
    "    \"üåç Mixed Language (HR-EN)\": {\n",
    "        \"text\": \"Potrebno je implementirati RAG system koji koristi BGE-M3 embeddings za hrvatski jezik. The system should support both Croatian and English queries.\",\n",
    "        \"expected_language\": \"mixed\",\n",
    "        \"category\": \"code_switching\",\n",
    "        \"complexity\": \"bilingual_technical\"\n",
    "    },\n",
    "\n",
    "    \"üåç Mixed Language (EN-HR)\": {\n",
    "        \"text\": \"The new regulation states that minimalna plaƒáa ƒáe biti poveƒáana na 721,79 EUR mjeseƒçno starting from July 2025.\",\n",
    "        \"expected_language\": \"mixed\",\n",
    "        \"category\": \"code_switching\",\n",
    "        \"complexity\": \"bilingual_legal\"\n",
    "    },\n",
    "\n",
    "    \"üìä Numbers & Dates (HR)\": {\n",
    "        \"text\": \"Dana 15. studenog 2025. godine, ukupna vrijednost investicije iznosila je 1.250.000,00 EUR.\",\n",
    "        \"expected_language\": \"hr\",\n",
    "        \"category\": \"numerical_temporal\",\n",
    "        \"complexity\": \"formal_numerical\"\n",
    "    },\n",
    "\n",
    "    \"üìä Numbers & Dates (EN)\": {\n",
    "        \"text\": \"On November 15th, 2025, the total investment value reached ‚Ç¨1,250,000.00 with a 12.5% ROI.\",\n",
    "        \"expected_language\": \"en\",\n",
    "        \"category\": \"numerical_temporal\",\n",
    "        \"complexity\": \"business_numerical\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üåç Multilingual Test Cases Prepared:\")\n",
    "print(\"=\" * 60)\n",
    "for name, data in multilingual_test_cases.items():\n",
    "    print(f\"{name}\")\n",
    "    print(f\"   Expected: {data['expected_language']} | Category: {data['category']}\")\n",
    "    print(f\"   Text: {data['text'][:60]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Language Detection Implementation\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def detect_language_advanced(text):\n",
    "    \"\"\"\n",
    "    Advanced language detection for Croatian/English with confidence scoring.\n",
    "    \"\"\"\n",
    "    # Croatian-specific patterns\n",
    "    croatian_patterns = {\n",
    "        # Diacritics\n",
    "        'diacritics': r'[ƒçƒá≈æ≈°ƒë]',\n",
    "        # Croatian specific words\n",
    "        'common_words': r'\\b(je|su|za|na|u|od|do|se|i|a|ali|kada|kako|≈°to|koji|koja|koje|gdje|ovdje|tamo|sada|tada|ovo|to|mogu|moram|trebam|≈æelim|volim|imam|nema|ima|biti|jest|nije|jeste|hoƒáe|neƒáe|bi|bih|bismo|biste|bude|budem|budemo|budete|bio|bila|bilo|bili|bile)\\b',\n",
    "        # Croatian grammar patterns\n",
    "        'verb_endings': r'\\b\\w+(ati|iti|uti|ovati|evati|avati|ivati)\\b',\n",
    "        'noun_endings': r'\\b\\w+(ost|stvo|anje|enje|ica|nik|ar|ka|ac)\\b',\n",
    "        # Date patterns (Croatian)\n",
    "        'dates': r'\\b\\d{1,2}\\.\\s*(sijeƒçnja|veljaƒçe|o≈æujka|travnja|svibnja|lipnja|srpnja|kolovoza|rujna|listopada|studenoga|prosinca)\\s*\\d{4}\\.',\n",
    "        # Croatian currency format\n",
    "        'currency': r'\\d+[.,]\\d+\\s*EUR\\s*(mjeseƒçno|godi≈°nje|dnevno)',\n",
    "    }\n",
    "\n",
    "    # English-specific patterns\n",
    "    english_patterns = {\n",
    "        # English articles and prepositions\n",
    "        'articles': r'\\b(the|a|an)\\b',\n",
    "        'prepositions': r'\\b(of|in|to|for|with|on|at|by|from|about|through|during|before|after|above|below|between|among)\\b',\n",
    "        # English common words\n",
    "        'common_words': r'\\b(and|or|but|if|when|where|why|how|what|who|which|that|this|these|those|will|would|could|should|may|might|can|must|have|has|had|do|does|did|is|are|was|were|been|being|get|got|make|made|take|took|come|came|go|went|see|saw|know|knew|think|thought|say|said|tell|told|give|gave|find|found|use|used|work|worked|way|time|year|new|good|great|right|different|important|possible)\\b',\n",
    "        # English verb patterns\n",
    "        'verb_endings': r'\\b\\w+(ing|ed|er|est)\\b',\n",
    "        # English plurals\n",
    "        'plurals': r'\\b\\w+s\\b',\n",
    "        # Date patterns (English)\n",
    "        'dates': r'\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2}(st|nd|rd|th)?,?\\s*\\d{4}',\n",
    "    }\n",
    "\n",
    "    # Count pattern matches\n",
    "    croatian_score = 0\n",
    "    english_score = 0\n",
    "\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Croatian pattern scoring\n",
    "    for pattern_name, pattern in croatian_patterns.items():\n",
    "        matches = len(re.findall(pattern, text_lower))\n",
    "        weight = {\n",
    "            'diacritics': 5,        # Strong indicator\n",
    "            'common_words': 3,      # Very reliable\n",
    "            'verb_endings': 2,      # Moderate\n",
    "            'noun_endings': 2,      # Moderate\n",
    "            'dates': 4,             # Strong cultural indicator\n",
    "            'currency': 3           # Moderate cultural indicator\n",
    "        }.get(pattern_name, 1)\n",
    "        croatian_score += matches * weight\n",
    "\n",
    "    # English pattern scoring\n",
    "    for pattern_name, pattern in english_patterns.items():\n",
    "        matches = len(re.findall(pattern, text_lower))\n",
    "        weight = {\n",
    "            'articles': 4,          # Strong indicator (Croatian lacks articles)\n",
    "            'prepositions': 2,      # Moderate\n",
    "            'common_words': 3,      # Very reliable\n",
    "            'verb_endings': 2,      # Moderate\n",
    "            'plurals': 1,          # Weak (Croatian also has plurals)\n",
    "            'dates': 3             # Cultural indicator\n",
    "        }.get(pattern_name, 1)\n",
    "        english_score += matches * weight\n",
    "\n",
    "    # Length normalization\n",
    "    text_length = len(text.split())\n",
    "    if text_length > 0:\n",
    "        croatian_score = croatian_score / text_length\n",
    "        english_score = english_score / text_length\n",
    "\n",
    "    # Determine language and confidence\n",
    "    total_score = croatian_score + english_score\n",
    "\n",
    "    if total_score == 0:\n",
    "        return \"unknown\", 0.0, {\"croatian_score\": 0, \"english_score\": 0}\n",
    "\n",
    "    if croatian_score > english_score:\n",
    "        confidence = croatian_score / total_score\n",
    "        language = \"hr\"\n",
    "    elif english_score > croatian_score:\n",
    "        confidence = english_score / total_score\n",
    "        language = \"en\"\n",
    "    else:\n",
    "        confidence = 0.5\n",
    "        language = \"mixed\"\n",
    "\n",
    "    # Detect mixed language (if both scores are significant)\n",
    "    if min(croatian_score, english_score) / max(croatian_score, english_score) > 0.3:\n",
    "        language = \"mixed\"\n",
    "        confidence = 0.6  # Mixed content has inherent uncertainty\n",
    "\n",
    "    return language, confidence, {\n",
    "        \"croatian_score\": round(croatian_score, 3),\n",
    "        \"english_score\": round(english_score, 3),\n",
    "        \"total_score\": round(total_score, 3)\n",
    "    }\n",
    "\n",
    "print(\"üîç Advanced Language Detection Function Ready\")\n",
    "print(\"   Features: Pattern matching, confidence scoring, mixed-language detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test language detection on all examples\n",
    "print(\"üß™ Language Detection Testing & Evaluation\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "detection_results = []\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for test_name, test_data in multilingual_test_cases.items():\n",
    "    text = test_data['text']\n",
    "    expected = test_data['expected_language']\n",
    "    category = test_data['category']\n",
    "    complexity = test_data['complexity']\n",
    "\n",
    "    # Perform detection\n",
    "    detected_lang, confidence, scores = detect_language_advanced(text)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    is_correct = (detected_lang == expected) or (expected == \"mixed\" and detected_lang == \"mixed\")\n",
    "    if is_correct:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "    # Store results\n",
    "    detection_results.append({\n",
    "        'name': test_name,\n",
    "        'text_preview': text[:50] + \"...\",\n",
    "        'expected': expected,\n",
    "        'detected': detected_lang,\n",
    "        'confidence': confidence,\n",
    "        'correct': is_correct,\n",
    "        'category': category,\n",
    "        'complexity': complexity,\n",
    "        'scores': scores\n",
    "    })\n",
    "\n",
    "    # Display result\n",
    "    status = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
    "    print(f\"{status} {test_name}\")\n",
    "    print(f\"   Expected: {expected} | Detected: {detected_lang} | Confidence: {confidence:.3f}\")\n",
    "    print(f\"   Category: {category} | Complexity: {complexity}\")\n",
    "    print(f\"   Scores - HR: {scores['croatian_score']}, EN: {scores['english_score']}\")\n",
    "    print()\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"üéØ Overall Detection Accuracy: {accuracy:.1%} ({correct_predictions}/{total_predictions})\")\n",
    "\n",
    "# Category-wise accuracy\n",
    "category_accuracy = {}\n",
    "for result in detection_results:\n",
    "    category = result['category']\n",
    "    if category not in category_accuracy:\n",
    "        category_accuracy[category] = {'correct': 0, 'total': 0}\n",
    "    category_accuracy[category]['total'] += 1\n",
    "    if result['correct']:\n",
    "        category_accuracy[category]['correct'] += 1\n",
    "\n",
    "print(\"\\nüìä Category-wise Performance:\")\n",
    "for category, stats in category_accuracy.items():\n",
    "    acc = stats['correct'] / stats['total']\n",
    "    print(f\"   {category}: {acc:.1%} ({stats['correct']}/{stats['total']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize language detection results\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Prepare data for visualization\n",
    "languages = [r['detected'] for r in detection_results]\n",
    "confidences = [r['confidence'] for r in detection_results]\n",
    "categories = [r['category'] for r in detection_results]\n",
    "correctness = [r['correct'] for r in detection_results]\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('üåç Advanced Language Detection Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Language Distribution\n",
    "lang_counts = Counter(languages)\n",
    "colors = {'hr': '#FF6B6B', 'en': '#4ECDC4', 'mixed': '#45B7D1', 'unknown': '#FFA726'}\n",
    "lang_colors = [colors.get(lang, '#gray') for lang in lang_counts.keys()]\n",
    "\n",
    "bars1 = ax1.bar(lang_counts.keys(), lang_counts.values(), color=lang_colors)\n",
    "ax1.set_title('üîç Detected Language Distribution', fontweight='bold')\n",
    "ax1.set_ylabel('Count')\n",
    "for bar, count in zip(bars1, lang_counts.values()):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "             str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Confidence Score Distribution by Language\n",
    "lang_confidences = defaultdict(list)\n",
    "for result in detection_results:\n",
    "    lang_confidences[result['detected']].append(result['confidence'])\n",
    "\n",
    "positions = []\n",
    "confidence_data = []\n",
    "labels = []\n",
    "colors_violin = []\n",
    "\n",
    "for i, (lang, confs) in enumerate(lang_confidences.items()):\n",
    "    positions.append(i)\n",
    "    confidence_data.append(confs)\n",
    "    labels.append(f\"{lang}\\n(n={len(confs)})\")\n",
    "    colors_violin.append(colors.get(lang, '#gray'))\n",
    "\n",
    "if confidence_data:  # Only plot if we have data\n",
    "    violin_parts = ax2.violinplot(confidence_data, positions=positions)\n",
    "    for pc, color in zip(violin_parts['bodies'], colors_violin):\n",
    "        pc.set_facecolor(color)\n",
    "        pc.set_alpha(0.7)\n",
    "\n",
    "    ax2.set_title('üìä Confidence Score Distribution', fontweight='bold')\n",
    "    ax2.set_ylabel('Confidence Score')\n",
    "    ax2.set_xlabel('Detected Language')\n",
    "    ax2.set_xticks(positions)\n",
    "    ax2.set_xticklabels(labels)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Category Performance Analysis\n",
    "category_data = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "for result in detection_results:\n",
    "    cat = result['category']\n",
    "    category_data[cat]['total'] += 1\n",
    "    if result['correct']:\n",
    "        category_data[cat]['correct'] += 1\n",
    "\n",
    "categories_list = list(category_data.keys())\n",
    "accuracies = [category_data[cat]['correct'] / category_data[cat]['total']\n",
    "              for cat in categories_list]\n",
    "\n",
    "bars3 = ax3.barh(categories_list, accuracies, color='lightgreen')\n",
    "ax3.set_title('üéØ Accuracy by Content Category', fontweight='bold')\n",
    "ax3.set_xlabel('Accuracy')\n",
    "ax3.set_xlim(0, 1)\n",
    "for i, (bar, acc) in enumerate(zip(bars3, accuracies)):\n",
    "    ax3.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "             f'{acc:.1%}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "# 4. Confusion Matrix Style Analysis\n",
    "expected_langs = [r['expected'] for r in detection_results]\n",
    "detected_langs = [r['detected'] for r in detection_results]\n",
    "\n",
    "# Create confusion matrix data\n",
    "unique_langs = sorted(set(expected_langs + detected_langs))\n",
    "confusion_data = np.zeros((len(unique_langs), len(unique_langs)))\n",
    "\n",
    "for exp, det in zip(expected_langs, detected_langs):\n",
    "    exp_idx = unique_langs.index(exp)\n",
    "    det_idx = unique_langs.index(det)\n",
    "    confusion_data[exp_idx][det_idx] += 1\n",
    "\n",
    "# Plot confusion matrix\n",
    "im = ax4.imshow(confusion_data, cmap='Blues', aspect='auto')\n",
    "ax4.set_title('üîÄ Expected vs Detected Languages', fontweight='bold')\n",
    "ax4.set_xlabel('Detected Language')\n",
    "ax4.set_ylabel('Expected Language')\n",
    "ax4.set_xticks(range(len(unique_langs)))\n",
    "ax4.set_yticks(range(len(unique_langs)))\n",
    "ax4.set_xticklabels(unique_langs)\n",
    "ax4.set_yticklabels(unique_langs)\n",
    "\n",
    "# Add text annotations to confusion matrix\n",
    "for i in range(len(unique_langs)):\n",
    "    for j in range(len(unique_langs)):\n",
    "        text = ax4.text(j, i, int(confusion_data[i, j]),\n",
    "                       ha=\"center\", va=\"center\", color=\"black\" if confusion_data[i, j] < confusion_data.max()/2 else \"white\",\n",
    "                       fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìà Detection Performance Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üéØ Overall Accuracy: {accuracy:.1%}\")\n",
    "print(f\"üìä Average Confidence: {np.mean(confidences):.3f}\")\n",
    "print(f\"üìê Confidence Std Dev: {np.std(confidences):.3f}\")\n",
    "print(f\"üîç Languages Detected: {', '.join(lang_counts.keys())}\")\n",
    "print(f\"üìÇ Categories Tested: {len(set(categories))}\")\n",
    "\n",
    "# Best and worst performing categories\n",
    "best_category = max(category_accuracy.items(), key=lambda x: x[1]['correct']/x[1]['total'])\n",
    "worst_category = min(category_accuracy.items(), key=lambda x: x[1]['correct']/x[1]['total'])\n",
    "\n",
    "print(f\"\\nüèÜ Best Category: {best_category[0]} ({best_category[1]['correct']}/{best_category[1]['total']} = {best_category[1]['correct']/best_category[1]['total']:.1%})\")\n",
    "print(f\"‚ö†Ô∏è  Most Challenging: {worst_category[0]} ({worst_category[1]['correct']}/{worst_category[1]['total']} = {worst_category[1]['correct']/worst_category[1]['total']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Croatian Language Quality Assessment\n",
    "\n",
    "Let's implement specific quality checks for Croatian language generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_croatian_quality(text: str) -> Dict[str, float]:\n",
    "    \"\"\"Assess Croatian language quality of generated text.\"\"\"\n",
    "\n",
    "    quality_scores = {}\n",
    "\n",
    "    # 1. Diacritic usage (crucial for Croatian)\n",
    "    croatian_diacritics = 'ƒçƒá≈°≈æƒëƒåƒÜ≈†≈Ωƒê'\n",
    "    diacritic_count = sum(1 for char in text if char in croatian_diacritics)\n",
    "    total_chars = len(text)\n",
    "    quality_scores['diacritic_usage'] = min(diacritic_count / max(total_chars * 0.02, 1), 1.0)\n",
    "\n",
    "    # 2. Croatian word frequency\n",
    "    croatian_common_words = {\n",
    "        'je', 'se', 'na', 'za', 'da', 'su', 'ili', 'ako', 'kad', '≈°to',\n",
    "        'biti', 'imati', 'moƒái', 'htjeti', 'trebati', 'doƒái', 'vidjeti',\n",
    "        'zagreb', 'hrvatska', 'dubrovnik', 'split', 'rijeka', 'grad',\n",
    "        'glavni', 'veliki', 'lijep', 'va≈æan', 'poznaj'\n",
    "    }\n",
    "\n",
    "    words = text.lower().split()\n",
    "    croatian_word_count = sum(1 for word in words if any(cw in word for cw in croatian_common_words))\n",
    "    quality_scores['croatian_vocabulary'] = min(croatian_word_count / max(len(words) * 0.3, 1), 1.0)\n",
    "\n",
    "    # 3. Sentence structure (Croatian tends to have longer, more complex sentences)\n",
    "    sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "    avg_sentence_length = len(words) / max(sentences, 1)\n",
    "    # Croatian sentences are typically 10-20 words\n",
    "    quality_scores['sentence_structure'] = 1.0 - abs(avg_sentence_length - 15) / 15\n",
    "    quality_scores['sentence_structure'] = max(0.0, min(1.0, quality_scores['sentence_structure']))\n",
    "\n",
    "    # 4. Cultural context indicators\n",
    "    cultural_terms = {\n",
    "        'jadran', 'dalmacija', 'slavonija', 'istra', 'biser', 'ba≈°tina',\n",
    "        'nacionalni park', 'unesco', 'kulturni', 'povijesni', 'tradicija'\n",
    "    }\n",
    "\n",
    "    cultural_mentions = sum(1 for term in cultural_terms if term in text.lower())\n",
    "    quality_scores['cultural_context'] = min(cultural_mentions / 2.0, 1.0)  # Normalize to max 2 mentions\n",
    "\n",
    "    # 5. Overall quality score\n",
    "    weights = {\n",
    "        'diacritic_usage': 0.3,\n",
    "        'croatian_vocabulary': 0.3,\n",
    "        'sentence_structure': 0.2,\n",
    "        'cultural_context': 0.2\n",
    "    }\n",
    "\n",
    "    quality_scores['overall'] = sum(\n",
    "        score * weights[metric]\n",
    "        for metric, score in quality_scores.items()\n",
    "        if metric in weights\n",
    "    )\n",
    "\n",
    "    return quality_scores\n",
    "\n",
    "# Test Croatian quality assessment\n",
    "test_texts = {\n",
    "    \"High Quality Croatian\": \"Zagreb je glavni i najveƒái grad Republike Hrvatske, smje≈°ten na sjeverozapadu zemlje uz rijeku Savu. Grad je va≈æno politiƒçko, gospodarsko i kulturno sredi≈°te, te dom mnogih znaƒçajnih institucija i kulturnih znamenitosti.\",\n",
    "\n",
    "    \"Medium Quality\": \"Zagreb je glavni grad Hrvatske. Ima puno stanovnika i nalazi se u hrvatskoj. Grad je poznat po svojoj ljepoti.\",\n",
    "\n",
    "    \"Low Quality (No Diacritics)\": \"Zagreb je glavni grad Hrvatske. Grad ima puno stanovnika i poznat je po svojoj lepoti i kulturi.\",\n",
    "\n",
    "    \"Cultural Context Rich\": \"Dubrovnik, poznat kao 'biser Jadrana', je grad s bogatom povijesti smje≈°ten u Dalmaciji. UNESCO je uvrstio Dubrovnik na popis svjetske ba≈°tine zbog njegovih izuzetnih kulturnih vrijednosti.\"\n",
    "}\n",
    "\n",
    "print(\"üá≠üá∑ Croatian Language Quality Assessment:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "quality_results = []\n",
    "\n",
    "for category, text in test_texts.items():\n",
    "    scores = assess_croatian_quality(text)\n",
    "\n",
    "    print(f\"\\nüìù {category}:\")\n",
    "    print(f\"Text: {text[:80]}...\")\n",
    "    print(f\"\\nüìä Quality Scores:\")\n",
    "\n",
    "    for metric, score in scores.items():\n",
    "        if metric != 'overall':\n",
    "            print(f\"  {metric.replace('_', ' ').title()}: {score:.3f}\")\n",
    "\n",
    "    print(f\"  üéØ Overall Quality: {scores['overall']:.3f}\")\n",
    "\n",
    "    # Quality rating\n",
    "    overall = scores['overall']\n",
    "    if overall >= 0.8:\n",
    "        rating = \"üü¢ Excellent\"\n",
    "    elif overall >= 0.6:\n",
    "        rating = \"üü° Good\"\n",
    "    elif overall >= 0.4:\n",
    "        rating = \"üü† Fair\"\n",
    "    else:\n",
    "        rating = \"üî¥ Poor\"\n",
    "\n",
    "    print(f\"  Rating: {rating}\")\n",
    "\n",
    "    quality_results.append({\n",
    "        'category': category,\n",
    "        'overall_score': scores['overall'],\n",
    "        'scores': scores\n",
    "    })\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Visualize quality assessment\n",
    "categories = [r['category'] for r in quality_results]\n",
    "overall_scores = [r['overall_score'] for r in quality_results]\n",
    "\n",
    "# Detailed scores breakdown\n",
    "metrics = ['diacritic_usage', 'croatian_vocabulary', 'sentence_structure', 'cultural_context']\n",
    "metric_scores = {metric: [r['scores'][metric] for r in quality_results] for metric in metrics}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Overall quality scores\n",
    "bars = ax1.barh(categories, overall_scores, color=['green', 'orange', 'red', 'blue'])\n",
    "ax1.set_title('Overall Croatian Quality Scores', weight='bold')\n",
    "ax1.set_xlabel('Quality Score')\n",
    "ax1.set_xlim(0, 1)\n",
    "\n",
    "for bar, score in zip(bars, overall_scores):\n",
    "    ax1.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "             f'{score:.3f}', ha='left', va='center', weight='bold')\n",
    "\n",
    "# Quality metrics breakdown\n",
    "x = np.arange(len(categories))\n",
    "width = 0.2\n",
    "colors = ['lightblue', 'lightgreen', 'lightsalmon', 'plum']\n",
    "\n",
    "for i, (metric, scores) in enumerate(metric_scores.items()):\n",
    "    ax2.bar(x + i * width, scores, width, label=metric.replace('_', ' ').title(), color=colors[i])\n",
    "\n",
    "ax2.set_title('Quality Metrics Breakdown', weight='bold')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_xlabel('Text Category')\n",
    "ax2.set_xticks(x + width * 1.5)\n",
    "ax2.set_xticklabels([cat.replace(' ', '\\n') for cat in categories], fontsize=8)\n",
    "ax2.legend(fontsize=8)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Croatian quality assessment complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices and Optimization\n",
    "\n",
    "Key lessons learned for Croatian RAG generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices summary\n",
    "best_practices = {\n",
    "    \"Prompt Engineering\": {\n",
    "        \"‚úÖ Do\": [\n",
    "            \"Use Croatian system prompts consistently\",\n",
    "            \"Include cultural context instructions\",\n",
    "            \"Specify formal Croatian language style\",\n",
    "            \"Match prompt template to query type\",\n",
    "            \"Preserve diacritic encoding throughout\"\n",
    "        ],\n",
    "        \"‚ùå Don't\": [\n",
    "            \"Mix languages in system prompts\",\n",
    "            \"Ignore Croatian cultural context\",\n",
    "            \"Use generic English templates\",\n",
    "            \"Assume model understands Croatian nuances\"\n",
    "        ]\n",
    "    },\n",
    "    \"Model Configuration\": {\n",
    "        \"‚úÖ Do\": [\n",
    "            \"Set temperature 0.6-0.8 for Croatian\",\n",
    "            \"Use sufficient max tokens (1500-2000)\",\n",
    "            \"Enable diacritic preservation\",\n",
    "            \"Configure timeout for longer responses\"\n",
    "        ],\n",
    "        \"‚ùå Don't\": [\n",
    "            \"Use too low temperature (rigid responses)\",\n",
    "            \"Use too high temperature (inconsistent quality)\",\n",
    "            \"Limit tokens too strictly\",\n",
    "            \"Ignore Croatian-specific settings\"\n",
    "        ]\n",
    "    },\n",
    "    \"Response Processing\": {\n",
    "        \"‚úÖ Do\": [\n",
    "            \"Parse and validate Croatian content\",\n",
    "            \"Check for diacritic preservation\",\n",
    "            \"Assess cultural context accuracy\",\n",
    "            \"Monitor confidence scores\",\n",
    "            \"Extract and validate source references\"\n",
    "        ],\n",
    "        \"‚ùå Don't\": [\n",
    "            \"Accept responses without validation\",\n",
    "            \"Ignore language detection results\",\n",
    "            \"Skip quality assessment\",\n",
    "            \"Trust confidence scores blindly\"\n",
    "        ]\n",
    "    },\n",
    "    \"Performance Optimization\": {\n",
    "        \"‚úÖ Do\": [\n",
    "            \"Cache common Croatian patterns\",\n",
    "            \"Batch similar query types\",\n",
    "            \"Monitor generation times\",\n",
    "            \"Optimize context length\",\n",
    "            \"Use async processing for scalability\"\n",
    "        ],\n",
    "        \"‚ùå Don't\": [\n",
    "            \"Generate synchronously for multiple queries\",\n",
    "            \"Ignore performance metrics\",\n",
    "            \"Use excessive context length\",\n",
    "            \"Skip error handling\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üéØ Croatian RAG Generation Best Practices:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"\\nüìö {category}:\")\n",
    "\n",
    "    if \"‚úÖ Do\" in practices:\n",
    "        print(\"\\n‚úÖ Best Practices:\")\n",
    "        for practice in practices[\"‚úÖ Do\"]:\n",
    "            print(f\"  ‚Ä¢ {practice}\")\n",
    "\n",
    "    if \"‚ùå Don't\" in practices:\n",
    "        print(\"\\n‚ùå Avoid:\")\n",
    "        for practice in practices[\"‚ùå Don't\"]:\n",
    "            print(f\"  ‚Ä¢ {practice}\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Performance optimization tips\n",
    "print(\"\\n‚ö° Performance Optimization Tips:\")\n",
    "optimization_tips = [\n",
    "    \"Use llama3.1:8b for best Croatian support vs speed balance\",\n",
    "    \"Implement response caching for repeated queries\",\n",
    "    \"Batch process multiple queries when possible\",\n",
    "    \"Monitor GPU/CPU usage during generation\",\n",
    "    \"Set appropriate timeout values (30-60s)\",\n",
    "    \"Use streaming for long responses\",\n",
    "    \"Implement fallback strategies for failures\"\n",
    "]\n",
    "\n",
    "for tip in optimization_tips:\n",
    "    print(f\"  üîß {tip}\")\n",
    "\n",
    "print(\"\\nüìà Quality Improvement Strategies:\")\n",
    "quality_tips = [\n",
    "    \"Regularly assess Croatian diacritic usage\",\n",
    "    \"Monitor cultural context accuracy\",\n",
    "    \"Track confidence score distributions\",\n",
    "    \"Validate source reference extraction\",\n",
    "    \"Test with diverse Croatian query types\",\n",
    "    \"Implement human feedback loops\",\n",
    "    \"Update prompt templates based on performance\"\n",
    "]\n",
    "\n",
    "for tip in quality_tips:\n",
    "    print(f\"  üìä {tip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished in Step 4\n",
    "\n",
    "‚úÖ **Ollama Integration**: Built robust client for local LLM processing\n",
    "\n",
    "‚úÖ **Croatian Prompt Engineering**: Created specialized templates for different query types\n",
    "\n",
    "‚úÖ **Response Quality Assessment**: Implemented Croatian language quality metrics\n",
    "\n",
    "‚úÖ **Performance Monitoring**: Added comprehensive generation tracking\n",
    "\n",
    "‚úÖ **Cultural Context**: Integrated Croatian cultural awareness throughout\n",
    "\n",
    "### Key Technical Achievements\n",
    "\n",
    "1. **Local LLM Processing**: Complete privacy and control over generation\n",
    "2. **Croatian Language Support**: Diacritic preservation and cultural context\n",
    "3. **Adaptive Prompting**: Different templates for different query types\n",
    "4. **Quality Assessment**: Multi-metric evaluation system\n",
    "5. **Performance Optimization**: Async processing and monitoring\n",
    "\n",
    "### Next: Step 5 - Complete Pipeline Integration\n",
    "\n",
    "In the final step, we'll integrate all components into a complete RAG system:\n",
    "\n",
    "- **End-to-End Pipeline**: Connect preprocessing ‚Üí vector DB ‚Üí retrieval ‚Üí generation\n",
    "- **System Orchestration**: Manage the complete workflow\n",
    "- **Error Handling**: Robust failure recovery\n",
    "- **Performance Optimization**: System-wide efficiency improvements\n",
    "- **Evaluation Framework**: Complete system assessment\n",
    "\n",
    "The generation system is now ready to produce high-quality Croatian responses using retrieved context. Let's move on to integrate everything into our final RAG pipeline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

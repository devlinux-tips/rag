# Croatian RAG System - Main Configuration
# Consolidated configuration file for all system components

# ============================================================================
# SHARED CONFIGURATION
# ============================================================================
[shared]
# Common directories (unified for all components)
cache_dir = "./data/cache"
metrics_dir = "./data/metrics"
models_dir = "./models"
logs_dir = "./logs"

# Common timeouts (shared across components)
default_timeout = 120.0
request_timeout = 120.0
processing_timeout = 300.0
embedding_timeout = 180.0
retrieval_timeout = 60.0
generation_timeout = 120.0

# Common model settings - PERFORMANCE OPTIMIZED
default_device = "cpu" # "cpu" "cuda"
default_batch_size = 32  # CPU performs better with smaller batches

# Context and chunk size standards
default_max_context_length = 2500
default_chunk_size = 512
default_chunk_overlap = 50
min_chunk_size = 100

# Search defaults
default_top_k = 5
similarity_threshold = 0.3

# ============================================================================
# LANGUAGE CONFIGURATION
# ============================================================================
[languages]
# Supported languages - add new languages here
# Convention: Language code maps directly to config file (hr -> hr.toml, en -> en.toml)
supported = ["hr", "en"]
default = "hr"
auto_detect = false  # For future implementation

# Language display names
[languages.names]
hr = "Croatian"
en = "English"

# ============================================================================
# PROJECT SETTINGS
# ============================================================================
[project]
name = "Croatian RAG System"
version = "1.0.0"
description = "Advanced RAG system optimized for Croatian language"
author = "RAG Team"

[paths]
# Multi-tenant base directories
data_base_dir = "/data"
models_base_dir = "./models"
system_dir = "./system"

# Multi-tenant path templates - simplified since only documents are used
# Templates use {variable} format and are rendered with tenant/user/language data
tenant_root_template = "{data_base_dir}/{tenant_slug}"
user_documents_template = "{data_base_dir}/{tenant_slug}/users/{user_id}/{language}"
tenant_shared_template = "{data_base_dir}/{tenant_slug}/{language}"  # Tenant level = shared by default
# Processed folders are created but never used - keeping for backward compatibility
user_processed_template = "{data_base_dir}/{tenant_slug}/users/{user_id}/processed/{language}"
tenant_processed_template = "{data_base_dir}/{tenant_slug}/processed/{language}"
chromadb_path_template = "{data_base_dir}/{tenant_slug}/vectordb"
models_path_template = "{models_base_dir}/{tenant_slug}/{language}"


# System-wide temp directory
temp_dir = "./temp"

# Language-specific subdirectories (handled by templates)
use_language_subdirs = true

[logging]
backends = ["console"]
level = "TRACE"
format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
log_to_file = true

# ============================================================================
# VECTOR DATABASE CONFIGURATION
# ============================================================================
[vectordb]
# Provider selection: "chromadb" or "weaviate" - NO FALLBACKS
provider = "weaviate"

# Shared settings across all providers
collection_name_template = "{tenant}_{user}_{language}_documents"
distance_metric = "cosine"
batch_size = 500
timeout = 60.0
max_retries = 3
retry_delay = 1.0

# ChromaDB-specific configuration (kept for compatibility, not tested)
[vectordb.chromadb]
db_path_template = "{data_base_dir}/{tenant_slug}/vectordb"
persist = true
allow_reset = true
anonymized_telemetry = false
heartbeat_interval = 30
max_batch_size = 1000

# Weaviate-specific configuration (primary focus)
[vectordb.weaviate]
host = "localhost"  # Local Weaviate installation
port = 8080
grpc_port = 50051
scheme = "http"
vectorizer = "none"  # Use custom embeddings - NO FALLBACKS
timeout = 60.0
startup_period = 10

# Additional headers for authentication (if needed)
[vectordb.weaviate.additional_headers]
# Add headers as needed, no defaults

# HNSW index configuration for optimal performance with 244GB RAM
[vectordb.weaviate.index]
type = "hnsw"
ef_construction = 200
ef = 100
max_connections = 32
ef_dynamic = 100
cleanup_interval_seconds = 300
vector_cache_max_objects = 2000000

# Compression configuration for memory efficiency
[vectordb.weaviate.compression]
enabled = true
type = "sq"  # "sq" (scalar quantization) or "pq" (product quantization)
rescore_limit = 1000
training_limit = 50000
cache = true

# Backup and recovery settings
[vectordb.weaviate.backup]
enabled = false
backend = "filesystem"
backup_id = ""
include_meta = true

# ============================================================================
# EMBEDDING CONFIGURATION
# ============================================================================
[embeddings]
# Primary embedding model settings - NO FALLBACKS
model_name = "BAAI/bge-m3"  # Primary multilingual model
device = "cpu"
torch_dtype = "float32"
max_seq_length = 512
batch_size = 32  # REVERTED: Large batches (200) were 10x slower on CPU - smaller batches perform better
normalize_embeddings = true
use_safetensors = true
trust_remote_code = false
show_progress_bar = false

# Croatian-specific model override (if needed)
croatian_model_name = "classla/bcms-bertic"
croatian_model_dimensions = 768

# English-specific model override (if needed)
english_model_name = "BAAI/bge-large-en-v1.5"
english_model_dimensions = 1024

# Fallback multilingual model - EXPLICIT configuration
fallback_model_name = "BAAI/bge-m3"
fallback_model_dimensions = 1024

# Model loading configuration
cache_folder = "./models/cache"
local_files_only = false
revision = "main"

# ============================================================================
# ENHANCED CHUNKING CONFIGURATION
# ============================================================================
[chunking]
# Strategy selection - NO FALLBACKS, explicit choice required
strategy = "smart_legal"  # "sliding_window", "sentence", "paragraph", "smart_legal"

# Base chunking parameters - optimized for memory efficiency
chunk_size = 1024  # 2x larger than default for fewer chunks
chunk_overlap = 128  # 12.5% overlap for better context
min_chunk_size = 400  # No tiny meaningless chunks
max_chunk_size = 1536  # Hard upper limit

# Boundary respect settings
preserve_sentence_boundaries = true
respect_paragraph_breaks = true
preserve_document_structure = true
enable_smart_splitting = true

# Paragraph separators for chunking
paragraph_separators = ["\n\n", "\r\n\r\n"]
min_sentence_length = 20

# Advanced chunking options
enable_semantic_chunking = true
semantic_threshold = 0.7
max_chunks_per_document = 15  # Hard limit for memory management

# Global chunking settings
sentence_search_range = 100

# Smart legal chunking specific settings
[chunking.smart_legal]
enabled = true
preserve_section_boundaries = true
preserve_paragraph_structure = true
merge_short_paragraphs = true
section_min_length = 200
paragraph_min_length = 100

# Legal document structure indicators (Croatian)
legal_section_indicators = [
    "članak", "stavak", "točka", "podtočka", "odjeljak",
    "poglavlje", "dio", "odlomak", "alineja", "uvjet"
]

# Sliding window chunking settings (backup strategy)
[chunking.sliding_window]
sentence_search_range = 100
overlap_strategy = "sentence_boundary"

# Sentence-based chunking settings
[chunking.sentence]
min_sentences_per_chunk = 3
max_sentences_per_chunk = 10
sentence_overlap_count = 1

# Paragraph-based chunking settings
[chunking.paragraph]
min_paragraphs_per_chunk = 1
max_paragraphs_per_chunk = 3
paragraph_overlap_count = 0

# ============================================================================
# BATCH PROCESSING CONFIGURATION
# ============================================================================
[batch_processing]
# Core batch processing settings - PERFORMANCE OPTIMIZED
enabled = true
document_batch_size = 50  # OPTIMIZED: Smaller batches for incremental processing
embedding_batch_size = 32  # REVERTED: Match embeddings.batch_size (32) for consistency
vector_insert_batch_size = 1000  # OPTIMIZED: Reduced for incremental stability
max_parallel_workers = 8  # Utilize available CPU cores

# Memory management
memory_limit_gb = 200  # 80% of 244GB available RAM
memory_check_interval = 10  # Check memory every N batches
force_gc_interval = 50  # Force garbage collection every N batches

# Progress and checkpointing
checkpoint_interval = 100  # Save progress every N batches
progress_report_interval = 10  # Report progress every N batches
enable_progress_bar = true

# Error handling and resilience
max_retry_attempts = 3
retry_delay_seconds = 2.0
skip_failed_documents = false  # Fail fast - don't skip errors
continue_on_batch_failure = false  # Fail entire process on batch failure

# Performance optimization
prefetch_batches = 2  # Pre-load next batches for efficiency
async_processing = true
thread_pool_size = 8

# ============================================================================
# DOCUMENT PROCESSING CONFIGURATION
# ============================================================================
[processing]
# Document processing settings
sentence_chunk_overlap = 2
preserve_paragraphs = true
enable_smart_chunking = true
respect_document_structure = true
max_concurrent_documents = 10

[extraction]
# Document extraction settings
supported_formats = [".pdf", ".docx", ".txt", ".html", ".md"]
preserve_formatting = true
extract_metadata = true
handle_images = false
ocr_enabled = false
max_file_size_mb = 50
enable_logging = true
encoding_detection = true
text_encodings = ["utf-8", "cp1252", "iso-8859-1", "iso-8859-2"]

[cleaning]
# Text cleaning settings
remove_extra_whitespace = true
multiple_whitespace = true
multiple_linebreaks = true
min_meaningful_words = 5
min_word_char_ratio = 0.3
normalize_unicode = true
preserve_formatting = false
remove_urls = false
remove_email_addresses = false
preserve_sentence_structure = true

# ============================================================================
# QUERY PROCESSING CONFIGURATION
# ============================================================================
[query_processing]
# Query enhancement settings
language = "hr"
expand_synonyms = false
normalize_case = true
remove_stopwords = true
min_query_length = 3
max_query_length = 500
max_expanded_terms = 10
enable_morphological_analysis = true
use_query_classification = true
enable_spell_check = false

# ============================================================================
# RETRIEVAL CONFIGURATION
# ============================================================================
[retrieval]
# Document retrieval settings
default_k = 5
max_k = 20
adaptive_retrieval = true
enable_reranking = true
diversity_lambda = 0.7
use_hybrid_search = true
enable_query_expansion = false

# Hierarchical retrieval similarity thresholds
[retrieval.similarity_thresholds]
semantic_focused = 0.75
default = 0.6
comprehensive = 0.4
strict = 0.85
factual = 0.8

# ============================================================================
# RANKING AND RERANKING CONFIGURATION
# ============================================================================
[ranking]
# Ranking method configuration
method = "language_enhanced"
enable_diversity = true
diversity_threshold = 0.8
boost_recent = false
boost_authoritative = false
content_length_factor = false
keyword_density_factor = false
language_specific_boost = true

[reranking]
# Reranking settings
enabled = true
model_name = "ms-marco-MultiBERT-L-12"
max_length = 512
batch_size = 4
top_k = 10
use_fp16 = false
normalize = true

# ============================================================================
# HYBRID RETRIEVAL CONFIGURATION
# ============================================================================
[hybrid_retrieval]
# Hybrid search weights
dense_weight = 0.7
sparse_weight = 0.3
fusion_method = "reciprocal_rank_fusion"
bm25_k1 = 1.2
bm25_b = 0.75

# ============================================================================
# SEARCH CONFIGURATION
# ============================================================================
[search]
# Search method settings
default_method = "hybrid"
max_context_length = 2500
rerank = true
include_metadata = true
include_distances = true

[search.weights]
semantic_weight = 0.7
keyword_weight = 0.3

# ============================================================================
# LLM CONFIGURATION
# ============================================================================
[ollama]
# Ollama LLM settings
base_url = "http://localhost:11434"
model = "qwen2.5:7b-instruct"
timeout = 30.0
temperature = 0.1
max_tokens = 2048
top_p = 0.9
top_k = 40
stream = true
keep_alive = "5m"
num_predict = 2048
repeat_penalty = 1.1
seed = -1
api_key = "ollama"
response_format = "ollama"

[ollama.endpoints]
health_check = "/api/tags"
chat_completions = "/api/chat"
models_list = "/api/tags"
streaming_chat = "/api/chat"

# ============================================================================
# DATABASE PROVIDER CONFIGURATION
# ============================================================================
[database]
provider = "postgresql"

[database.postgresql]
host = "postgres"  # Changed from localhost to Docker container name
port = 5432
database = "ragdb"
user = "raguser"
password = "x|B&h@p4F@o|k6t;~X]1A((Z.,RG"  # Keep the proper secure password
connection_timeout = 30
max_connections = 10
pool_min_size = 1
pool_max_size = 10

[database.surrealdb]
url = "ws://localhost:8000/rpc"
namespace = "rag_system"
database = "main"
username = "root"
password = "root"
connection_timeout = 30
max_connections = 10

[database.supabase]
url = "https://your-project.supabase.co"
service_role_key = "your-service-role-key"
anon_key = "your-anon-key"
enable_rls = true
connection_timeout = 30
max_connections = 10

[database.supabase.auth]
enable_signup = true
enable_email_confirmations = false
site_url = "http://localhost:3000"
jwt_expiry = 3600

[database.supabase.rls]
enforce_mfa_for_sensitive_operations = false
tenant_isolation_strict = true
enable_audit_logging = true

# ============================================================================
# OPENROUTER CONFIGURATION
# ============================================================================
[openrouter]
base_url = "https://openrouter.ai/api/v1"
# SECURITY: API key MUST be set via environment variable OPENROUTER_API_KEY
# NEVER commit API keys to git - use .env.local file instead
api_key = "${OPENROUTER_API_KEY}"
model = "qwen/qwen3-30b-a3b-instruct-2507"
timeout = 30.0
temperature = 0.1
max_tokens = 2048
stream = false

# ============================================================================
# MULTI-PROVIDER LLM CONFIGURATION
# ============================================================================
[llm]
primary_provider = "openrouter"
fallback_order = []  # NO FALLBACKS - OpenRouter only
auto_fallback = false

# ============================================================================
# RESPONSE PARSING CONFIGURATION
# ============================================================================
[response_parsing]
validate_responses = true
extract_confidence_scores = true
parse_citations = true
handle_incomplete_responses = false
max_response_length = 4096
min_response_length = 10
filter_hallucinations = true
require_source_grounding = true
confidence_threshold = 0.7
response_format = "ollama"
include_metadata = true

# ============================================================================
# FEATURES CONFIGURATION
# ============================================================================
[features]
enable_features = true
features_base_dir = "{data_base_dir}/features"
collection_name_template = "features_{feature_key}_{language}"
documents_template = "{features_base_dir}/{feature_name}/{language}"

[features.narodne_novine]
enabled = true
name = "Narodne Novine"

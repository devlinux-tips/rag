{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Generation System Learning\n",
    "## Local LLM Integration with Ollama for Croatian RAG\n",
    "\n",
    "This notebook explores Step 4 of our Croatian RAG system - the **Generation System** using Ollama for local LLM processing. We'll learn how to integrate local language models, create Croatian-optimized prompts, and parse responses effectively.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand local LLM integration benefits and challenges\n",
    "- Learn Croatian-specific prompt engineering techniques\n",
    "- Implement response parsing and quality assessment\n",
    "- Explore different generation strategies for various query types\n",
    "- Test the complete generation pipeline with Croatian content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.generation.ollama_client import (\n",
    "    OllamaClient, OllamaConfig, GenerationRequest, \n",
    "    GenerationResponse, create_ollama_client\n",
    ")\n",
    "from src.generation.prompt_templates import (\n",
    "    CroatianRAGPrompts, PromptBuilder,\n",
    "    get_prompt_for_query_type, create_prompt_builder\n",
    ")\n",
    "from src.generation.response_parser import (\n",
    "    CroatianResponseParser, ParsedResponse, create_response_parser\n",
    ")\n",
    "\n",
    "# Set up display options\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✅ Generation system imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Local LLM Generation\n",
    "\n",
    "### Why Local LLMs for Croatian RAG?\n",
    "\n",
    "**Privacy & Control**:\n",
    "- Documents never leave your machine\n",
    "- No data sent to external APIs\n",
    "- Full control over model behavior\n",
    "\n",
    "**Cost Efficiency**:\n",
    "- No per-query API costs\n",
    "- Unlimited usage after setup\n",
    "- Predictable resource usage\n",
    "\n",
    "**Croatian Language Support**:\n",
    "- Modern models handle Croatian well\n",
    "- Can fine-tune for specific domains\n",
    "- Custom prompt engineering for cultural context\n",
    "\n",
    "### Challenges with Local Generation\n",
    "\n",
    "- **Hardware Requirements**: Need sufficient RAM and compute\n",
    "- **Model Selection**: Choosing the right model for Croatian\n",
    "- **Quality Control**: Ensuring consistent, high-quality outputs\n",
    "- **Speed vs Quality**: Balancing response time with answer quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize local LLM generation architecture\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 10))\n",
    "\n",
    "# Components and their positions\n",
    "components = {\n",
    "    'Query Processor': (1, 8),\n",
    "    'Retrieval System': (1, 6),\n",
    "    'Context Chunks': (3, 6),\n",
    "    'Prompt Templates': (5, 8),\n",
    "    'Prompt Builder': (7, 8),\n",
    "    'Ollama LLM': (9, 6),\n",
    "    'Response Parser': (11, 6),\n",
    "    'Final Answer': (13, 6)\n",
    "}\n",
    "\n",
    "# Draw components\n",
    "for name, (x, y) in components.items():\n",
    "    if name == 'Ollama LLM':\n",
    "        # Highlight the LLM as the core component\n",
    "        rect = plt.Rectangle((x-0.8, y-0.4), 1.6, 0.8, \n",
    "                           facecolor='lightcoral', edgecolor='red', linewidth=2)\n",
    "    elif name in ['Prompt Templates', 'Prompt Builder', 'Response Parser']:\n",
    "        # Highlight generation-specific components\n",
    "        rect = plt.Rectangle((x-0.8, y-0.4), 1.6, 0.8, \n",
    "                           facecolor='lightblue', edgecolor='blue', linewidth=2)\n",
    "    else:\n",
    "        rect = plt.Rectangle((x-0.8, y-0.4), 1.6, 0.8, \n",
    "                           facecolor='lightgray', edgecolor='black')\n",
    "    \n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, y, name, ha='center', va='center', fontsize=9, weight='bold')\n",
    "\n",
    "# Draw data flow arrows\n",
    "arrows = [\n",
    "    ((1.8, 8), (4.2, 8)),      # Query → Templates\n",
    "    ((1.8, 6), (2.2, 6)),      # Retrieval → Context\n",
    "    ((3.8, 6), (6.2, 7.5)),    # Context → Prompt Builder\n",
    "    ((5.8, 8), (6.2, 8)),      # Templates → Builder\n",
    "    ((7.8, 8), (8.2, 6.5)),    # Builder → LLM\n",
    "    ((9.8, 6), (10.2, 6)),     # LLM → Parser\n",
    "    ((11.8, 6), (12.2, 6))     # Parser → Answer\n",
    "]\n",
    "\n",
    "for (x1, y1), (x2, y2) in arrows:\n",
    "    ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
    "                arrowprops=dict(arrowstyle='->', lw=2, color='darkgreen'))\n",
    "\n",
    "# Add Croatian-specific annotations\n",
    "croatian_features = [\n",
    "    (5, 9, \"Croatian Query\\nType Detection\"),\n",
    "    (7, 9, \"Cultural Context\\nIntegration\"),\n",
    "    (9, 4.5, \"Diacritic\\nPreservation\"),\n",
    "    (11, 4.5, \"Croatian Language\\nQuality Check\")\n",
    "]\n",
    "\n",
    "for x, y, text in croatian_features:\n",
    "    ax.text(x, y, text, ha='center', va='center', fontsize=8,\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightyellow', alpha=0.7))\n",
    "\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(3, 10)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title('Croatian RAG Generation System Architecture\\n(Step 4: Local LLM Integration)', \n",
    "            fontsize=14, weight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Generation system architecture visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ollama Client Configuration\n",
    "\n",
    "Let's explore the Ollama client and its Croatian-specific configuration options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure Ollama client\n",
    "config = OllamaConfig(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0.7,           # Balanced creativity vs consistency\n",
    "    max_tokens=2000,          # Sufficient for detailed Croatian responses\n",
    "    preserve_diacritics=True, # Essential for Croatian\n",
    "    prefer_formal_style=True, # Professional Croatian language\n",
    "    include_cultural_context=True  # Croatian cultural awareness\n",
    ")\n",
    "\n",
    "client = OllamaClient(config)\n",
    "\n",
    "print(\"🔧 Ollama Client Configuration:\")\n",
    "print(f\"Model: {config.model}\")\n",
    "print(f\"Temperature: {config.temperature}\")\n",
    "print(f\"Max Tokens: {config.max_tokens}\")\n",
    "print(f\"Preserve Diacritics: {config.preserve_diacritics}\")\n",
    "print(f\"Formal Style: {config.prefer_formal_style}\")\n",
    "print(f\"Cultural Context: {config.include_cultural_context}\")\n",
    "\n",
    "# Check if Ollama service is running\n",
    "is_healthy = client.health_check()\n",
    "print(f\"\\n🏥 Ollama Service Status: {'✅ Running' if is_healthy else '❌ Not Available'}\")\n",
    "\n",
    "if is_healthy:\n",
    "    available_models = client.get_available_models()\n",
    "    print(f\"📦 Available Models: {available_models}\")\n",
    "    \n",
    "    if config.model in available_models:\n",
    "        print(f\"✅ Model {config.model} is ready\")\n",
    "    else:\n",
    "        print(f\"⚠️  Model {config.model} needs to be pulled\")\n",
    "else:\n",
    "    print(\"ℹ️  To start Ollama: ollama serve\")\n",
    "    print(\"ℹ️  To pull model: ollama pull llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Croatian Prompt Engineering\n",
    "\n",
    "Effective prompt engineering is crucial for high-quality Croatian generation. Let's explore our template system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore different Croatian prompt templates\n",
    "template_examples = {\n",
    "    \"General Q&A\": CroatianRAGPrompts.QUESTION_ANSWERING,\n",
    "    \"Factual Questions\": CroatianRAGPrompts.FACTUAL_QA,\n",
    "    \"Explanatory\": CroatianRAGPrompts.EXPLANATORY,\n",
    "    \"Cultural Context\": CroatianRAGPrompts.CULTURAL_CONTEXT,\n",
    "    \"Tourism\": CroatianRAGPrompts.TOURISM,\n",
    "    \"Summarization\": CroatianRAGPrompts.SUMMARIZATION,\n",
    "    \"Comparison\": CroatianRAGPrompts.COMPARISON\n",
    "}\n",
    "\n",
    "print(\"🎯 Croatian Prompt Templates Overview:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, template in template_examples.items():\n",
    "    print(f\"\\n📋 {name} Template:\")\n",
    "    \n",
    "    # Show first 150 characters of system prompt\n",
    "    system_preview = template.system_prompt[:150] + \"...\" if len(template.system_prompt) > 150 else template.system_prompt\n",
    "    print(f\"System: {system_preview}\")\n",
    "    \n",
    "    # Show user template\n",
    "    print(f\"User: {template.user_template}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test automatic template selection for Croatian queries\n",
    "test_queries = {\n",
    "    \"Koji je glavni grad Hrvatske?\": \"Should select FACTUAL_QA\",\n",
    "    \"Objasni hrvatsku kulturu\": \"Should select CULTURAL_CONTEXT or EXPLANATORY\",\n",
    "    \"Najbolja mjesta za turizam u Istri\": \"Should select TOURISM\",\n",
    "    \"Sažmi povijest Dubrovnika\": \"Should select SUMMARIZATION\",\n",
    "    \"Usporedi Zagreb i Split\": \"Should select COMPARISON\",\n",
    "    \"Kako nastaju Plitvička jezera?\": \"Should select EXPLANATORY\",\n",
    "    \"Što je biser Jadrana?\": \"Should select CULTURAL_CONTEXT\"\n",
    "}\n",
    "\n",
    "print(\"🤖 Automatic Template Selection Test:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "template_names = {\n",
    "    CroatianRAGPrompts.FACTUAL_QA: \"FACTUAL_QA\",\n",
    "    CroatianRAGPrompts.EXPLANATORY: \"EXPLANATORY\", \n",
    "    CroatianRAGPrompts.CULTURAL_CONTEXT: \"CULTURAL_CONTEXT\",\n",
    "    CroatianRAGPrompts.TOURISM: \"TOURISM\",\n",
    "    CroatianRAGPrompts.SUMMARIZATION: \"SUMMARIZATION\",\n",
    "    CroatianRAGPrompts.COMPARISON: \"COMPARISON\",\n",
    "    CroatianRAGPrompts.QUESTION_ANSWERING: \"QUESTION_ANSWERING\"\n",
    "}\n",
    "\n",
    "for query, expected in test_queries.items():\n",
    "    selected_template = get_prompt_for_query_type(query)\n",
    "    template_name = template_names.get(selected_template, \"UNKNOWN\")\n",
    "    \n",
    "    print(f\"\\n📝 Query: {query}\")\n",
    "    print(f\"🎯 Selected: {template_name}\")\n",
    "    print(f\"💭 Expected: {expected}\")\n",
    "    \n",
    "    # Check if selection makes sense\n",
    "    if any(keyword in expected for keyword in [template_name]):\n",
    "        print(\"✅ Good selection\")\n",
    "    else:\n",
    "        print(\"⚠️  Check selection logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompt Building and Context Integration\n",
    "\n",
    "Let's see how prompts are built with context chunks and Croatian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Croatian context chunks\n",
    "croatian_context = [\n",
    "    \"Zagreb je glavni i najveći grad Republike Hrvatske. Smješten je na\"\n",
    "    \" sjeverozapadu zemlje, uz rijeku Savu. Zagreb ima oko 800.000 stanovnika\"\n",
    "    \" u gradskim granicama i preko 1.1 milijuna u široj gradskoj oblasti.\",\n",
    "    \n",
    "    \"Dubrovnik je grad u Dubrovačko-neretvanskoj županiji u Hrvatskoj\"\n",
    "    \" Dalmaciji. Poznat je kao 'biser Jadrana' zbog svoje izuzetne ljepote\"\n",
    "    \" i bogate povijesti. Dubrovnik je upisan na UNESCO-ov popis svjetske baštine.\",\n",
    "    \n",
    "    \"Plitvička jezera su nacionalni park u Hrvatskoj gorskoj regiji Lika.\"\n",
    "    \" Park je poznat po nizovima terasa od šesnaest jezera povezanih\"\n",
    "    \" slapovima i kaskadama. Također je UNESCO-ova svjetska baština.\"\n",
    "]\n",
    "\n",
    "# Test different query types with context\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"Koji je glavni grad Hrvatske?\",\n",
    "        \"type\": \"factual\",\n",
    "        \"context\": croatian_context[:1]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Objasni zašto je Dubrovnik poznat?\",\n",
    "        \"type\": \"cultural\", \n",
    "        \"context\": croatian_context[1:2]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Usporedi Zagreb i Dubrovnik\",\n",
    "        \"type\": \"comparison\",\n",
    "        \"context\": croatian_context[:2]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"🔨 Prompt Building Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    query = case[\"query\"]\n",
    "    context = case[\"context\"]\n",
    "    \n",
    "    # Build prompt\n",
    "    builder = create_prompt_builder(query)\n",
    "    system_prompt, user_prompt = builder.build_prompt(query, context)\n",
    "    \n",
    "    print(f\"\\n📝 Example {i}: {case['type'].title()} Query\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"\\n🛠️  System Prompt (first 200 chars):\")\n",
    "    print(system_prompt[:200] + \"...\")\n",
    "    \n",
    "    print(f\"\\n👤 User Prompt:\")\n",
    "    print(user_prompt)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generation Testing\n",
    "\n",
    "Let's test the actual generation with our Croatian context (requires Ollama to be running)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generation with Croatian content\n",
    "async def test_croatian_generation():\n",
    "    \"\"\"Test Croatian text generation.\"\"\"\n",
    "    if not client.health_check():\n",
    "        print(\"❌ Ollama service not available. Please start with: ollama serve\")\n",
    "        return\n",
    "    \n",
    "    # Test queries with different complexity\n",
    "    test_requests = [\n",
    "        {\n",
    "            \"query\": \"Što je Zagreb?\",\n",
    "            \"context\": [croatian_context[0]],\n",
    "            \"type\": \"factual\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Zašto se Dubrovnik naziva 'biser Jadrana'?\",\n",
    "            \"context\": [croatian_context[1]],\n",
    "            \"type\": \"cultural\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Objasni značaj Plitvičkih jezera\", \n",
    "            \"context\": [croatian_context[2]],\n",
    "            \"type\": \"explanatory\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(\"🚀 Testing Croatian Generation:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, test_case in enumerate(test_requests, 1):\n",
    "        print(f\"\\n🔄 Test {i}: {test_case['type'].title()} Query\")\n",
    "        print(f\"Query: {test_case['query']}\")\n",
    "        \n",
    "        # Build the request\n",
    "        builder = create_prompt_builder(test_case[\"query\"])\n",
    "        system_prompt, user_prompt = builder.build_prompt(\n",
    "            test_case[\"query\"], \n",
    "            test_case[\"context\"]\n",
    "        )\n",
    "        \n",
    "        request = GenerationRequest(\n",
    "            prompt=user_prompt,\n",
    "            context=test_case[\"context\"],\n",
    "            query=test_case[\"query\"],\n",
    "            query_type=test_case[\"type\"],\n",
    "            language=\"hr\"\n",
    "        )\n",
    "        \n",
    "        # Generate response\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            async with OllamaClient(config) as async_client:\n",
    "                response = await async_client.generate_text_async(request)\n",
    "                \n",
    "                generation_time = time.time() - start_time\n",
    "                \n",
    "                print(f\"⏱️  Generation Time: {generation_time:.2f}s\")\n",
    "                print(f\"🎯 Confidence: {response.confidence:.3f}\")\n",
    "                print(f\"📊 Tokens Used: {response.tokens_used}\")\n",
    "                print(f\"\\n💬 Response:\")\n",
    "                print(response.text)\n",
    "                \n",
    "                # Check for Croatian content\n",
    "                if response.has_croatian_content:\n",
    "                    print(\"✅ Contains Croatian content\")\n",
    "                else:\n",
    "                    print(\"⚠️  Low Croatian content detected\")\n",
    "                \n",
    "                results.append({\n",
    "                    'query': test_case['query'],\n",
    "                    'response': response.text,\n",
    "                    'confidence': response.confidence,\n",
    "                    'generation_time': generation_time,\n",
    "                    'tokens': response.tokens_used,\n",
    "                    'croatian_content': response.has_croatian_content\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}\")\n",
    "            results.append({\n",
    "                'query': test_case['query'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the test\n",
    "generation_results = await test_croatian_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Response Parsing and Quality Assessment\n",
    "\n",
    "Let's explore how we parse and assess the quality of generated Croatian responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test response parsing with various Croatian responses\n",
    "parser = create_response_parser()\n",
    "\n",
    "# Sample responses for testing\n",
    "test_responses = {\n",
    "    \"High Quality\": \"Zagreb je glavni i najveći grad Republike Hrvatske, smješten na sjeverozapadu zemlje uz rijeku Savu. Grad ima bogatu povijest i kulturnu baštinu, te je važno političko, gospodarsko i kulturno središte zemlje.\",\n",
    "    \n",
    "    \"Medium Quality\": \"Zagreb je glavni grad. Možda ima oko 800 tisuća stanovnika, čini se da je važan grad u Hrvatskoj.\",\n",
    "    \n",
    "    \"Low Quality\": \"Ne znam točno što je Zagreb, nema dovoljno informacija u dostupnim dokumentima.\",\n",
    "    \n",
    "    \"With Sources\": \"Zagreb je glavni grad Hrvatske [Dokument 1]. Prema dokumentu, grad ima oko 800.000 stanovnika i smješten je uz rijeku Savu.\",\n",
    "    \n",
    "    \"Mixed Language\": \"Zagreb is the capital city, ali također je i najveći grad u hrvatskoj.\"\n",
    "}\n",
    "\n",
    "print(\"🔍 Response Parsing Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "parsing_results = []\n",
    "\n",
    "for category, response_text in test_responses.items():\n",
    "    parsed = parser.parse_response(\n",
    "        response_text, \n",
    "        query=\"Što je Zagreb?\", \n",
    "        context_chunks=[\"Zagreb context...\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📝 {category} Response:\")\n",
    "    print(f\"Text: {response_text[:100]}...\")\n",
    "    print(f\"🎯 Confidence: {parsed.confidence:.3f}\")\n",
    "    print(f\"🏳️  Language: {parsed.language}\")\n",
    "    print(f\"✅ Has Answer: {parsed.has_answer}\")\n",
    "    print(f\"📚 Sources: {len(parsed.sources_mentioned)}\")\n",
    "    \n",
    "    if parsed.sources_mentioned:\n",
    "        print(f\"   Sources: {parsed.sources_mentioned}\")\n",
    "    \n",
    "    parsing_results.append({\n",
    "        'category': category,\n",
    "        'confidence': parsed.confidence,\n",
    "        'language': parsed.language,\n",
    "        'has_answer': parsed.has_answer,\n",
    "        'sources_count': len(parsed.sources_mentioned)\n",
    "    })\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Visualize parsing results\n",
    "categories = [r['category'] for r in parsing_results]\n",
    "confidences = [r['confidence'] for r in parsing_results]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Confidence scores\n",
    "bars = ax1.bar(categories, confidences, color=['green', 'orange', 'red', 'blue', 'purple'])\n",
    "ax1.set_title('Response Quality Assessment\\n(Confidence Scores)', weight='bold')\n",
    "ax1.set_ylabel('Confidence Score')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, conf in zip(bars, confidences):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "             f'{conf:.3f}', ha='center', va='bottom', weight='bold')\n",
    "\n",
    "# Language distribution\n",
    "languages = [r['language'] for r in parsing_results]\n",
    "lang_counts = {lang: languages.count(lang) for lang in set(languages)}\n",
    "\n",
    "ax2.pie(lang_counts.values(), labels=lang_counts.keys(), autopct='%1.1f%%',\n",
    "        colors=['lightblue', 'lightcoral', 'lightgray'])\n",
    "ax2.set_title('Language Detection Results', weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Response parsing analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generation Performance Analysis\n",
    "\n",
    "Let's analyze the performance characteristics of our generation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze generation results if we have them\n",
    "if generation_results and not any('error' in result for result in generation_results):\n",
    "    print(\"📈 Generation Performance Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Extract metrics\n",
    "    queries = [r['query'] for r in generation_results]\n",
    "    confidences = [r['confidence'] for r in generation_results]\n",
    "    times = [r['generation_time'] for r in generation_results]\n",
    "    tokens = [r['tokens'] for r in generation_results]\n",
    "    croatian_content = [r['croatian_content'] for r in generation_results]\n",
    "    \n",
    "    # Performance statistics\n",
    "    avg_confidence = np.mean(confidences)\n",
    "    avg_time = np.mean(times)\n",
    "    avg_tokens = np.mean(tokens)\n",
    "    croatian_percentage = (sum(croatian_content) / len(croatian_content)) * 100\n",
    "    \n",
    "    print(f\"\\n📊 Performance Metrics:\")\n",
    "    print(f\"Average Confidence: {avg_confidence:.3f}\")\n",
    "    print(f\"Average Generation Time: {avg_time:.2f}s\")\n",
    "    print(f\"Average Tokens Generated: {avg_tokens:.0f}\")\n",
    "    print(f\"Croatian Content Rate: {croatian_percentage:.1f}%\")\n",
    "    print(f\"Tokens per Second: {avg_tokens/avg_time:.1f}\")\n",
    "    \n",
    "    # Visualize performance\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Confidence by query\n",
    "    bars1 = ax1.bar(range(len(queries)), confidences, color='lightblue')\n",
    "    ax1.set_title('Confidence by Query', weight='bold')\n",
    "    ax1.set_ylabel('Confidence Score')\n",
    "    ax1.set_xticks(range(len(queries)))\n",
    "    ax1.set_xticklabels([f'Q{i+1}' for i in range(len(queries))])\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    for bar, conf in zip(bars1, confidences):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                 f'{conf:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Generation time by query\n",
    "    bars2 = ax2.bar(range(len(queries)), times, color='lightcoral')\n",
    "    ax2.set_title('Generation Time by Query', weight='bold')\n",
    "    ax2.set_ylabel('Time (seconds)')\n",
    "    ax2.set_xticks(range(len(queries)))\n",
    "    ax2.set_xticklabels([f'Q{i+1}' for i in range(len(queries))])\n",
    "    \n",
    "    for bar, time_val in zip(bars2, times):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                 f'{time_val:.1f}s', ha='center', va='bottom')\n",
    "    \n",
    "    # Tokens generated\n",
    "    bars3 = ax3.bar(range(len(queries)), tokens, color='lightgreen')\n",
    "    ax3.set_title('Tokens Generated by Query', weight='bold')\n",
    "    ax3.set_ylabel('Token Count')\n",
    "    ax3.set_xticks(range(len(queries)))\n",
    "    ax3.set_xticklabels([f'Q{i+1}' for i in range(len(queries))])\n",
    "    \n",
    "    for bar, token_count in zip(bars3, tokens):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n",
    "                 f'{token_count}', ha='center', va='bottom')\n",
    "    \n",
    "    # Croatian content detection\n",
    "    croatian_labels = ['Croatian Content', 'Non-Croatian']\n",
    "    croatian_counts = [sum(croatian_content), len(croatian_content) - sum(croatian_content)]\n",
    "    ax4.pie(croatian_counts, labels=croatian_labels, autopct='%1.1f%%',\n",
    "            colors=['lightblue', 'lightgray'])\n",
    "    ax4.set_title('Croatian Content Detection', weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️  No generation results available for analysis.\")\n",
    "    print(\"   Either Ollama is not running or there were errors during generation.\")\n",
    "    print(\"\\n📊 Simulated Performance Metrics (Example):\")\n",
    "    \n",
    "    # Show example metrics\n",
    "    simulated_metrics = {\n",
    "        \"Average Confidence\": 0.756,\n",
    "        \"Average Generation Time\": 2.3,\n",
    "        \"Average Tokens Generated\": 127,\n",
    "        \"Croatian Content Rate\": 92.3,\n",
    "        \"Tokens per Second\": 55.2\n",
    "    }\n",
    "    \n",
    "    for metric, value in simulated_metrics.items():\n",
    "        if \"Time\" in metric:\n",
    "            print(f\"{metric}: {value}s\")\n",
    "        elif \"Rate\" in metric or \"per Second\" in metric:\n",
    "            print(f\"{metric}: {value}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Croatian Language Quality Assessment\n",
    "\n",
    "Let's implement specific quality checks for Croatian language generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_croatian_quality(text: str) -> Dict[str, float]:\n",
    "    \"\"\"Assess Croatian language quality of generated text.\"\"\"\n",
    "    \n",
    "    quality_scores = {}\n",
    "    \n",
    "    # 1. Diacritic usage (crucial for Croatian)\n",
    "    croatian_diacritics = 'čćšžđČĆŠŽĐ'\n",
    "    diacritic_count = sum(1 for char in text if char in croatian_diacritics)\n",
    "    total_chars = len(text)\n",
    "    quality_scores['diacritic_usage'] = min(diacritic_count / max(total_chars * 0.02, 1), 1.0)\n",
    "    \n",
    "    # 2. Croatian word frequency\n",
    "    croatian_common_words = {\n",
    "        'je', 'se', 'na', 'za', 'da', 'su', 'ili', 'ako', 'kad', 'što',\n",
    "        'biti', 'imati', 'moći', 'htjeti', 'trebati', 'doći', 'vidjeti',\n",
    "        'zagreb', 'hrvatska', 'dubrovnik', 'split', 'rijeka', 'grad',\n",
    "        'glavni', 'veliki', 'lijep', 'važan', 'poznaj'\n",
    "    }\n",
    "    \n",
    "    words = text.lower().split()\n",
    "    croatian_word_count = sum(1 for word in words if any(cw in word for cw in croatian_common_words))\n",
    "    quality_scores['croatian_vocabulary'] = min(croatian_word_count / max(len(words) * 0.3, 1), 1.0)\n",
    "    \n",
    "    # 3. Sentence structure (Croatian tends to have longer, more complex sentences)\n",
    "    sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "    avg_sentence_length = len(words) / max(sentences, 1)\n",
    "    # Croatian sentences are typically 10-20 words\n",
    "    quality_scores['sentence_structure'] = 1.0 - abs(avg_sentence_length - 15) / 15\n",
    "    quality_scores['sentence_structure'] = max(0.0, min(1.0, quality_scores['sentence_structure']))\n",
    "    \n",
    "    # 4. Cultural context indicators\n",
    "    cultural_terms = {\n",
    "        'jadran', 'dalmacija', 'slavonija', 'istra', 'biser', 'baština',\n",
    "        'nacionalni park', 'unesco', 'kulturni', 'povijesni', 'tradicija'\n",
    "    }\n",
    "    \n",
    "    cultural_mentions = sum(1 for term in cultural_terms if term in text.lower())\n",
    "    quality_scores['cultural_context'] = min(cultural_mentions / 2.0, 1.0)  # Normalize to max 2 mentions\n",
    "    \n",
    "    # 5. Overall quality score\n",
    "    weights = {\n",
    "        'diacritic_usage': 0.3,\n",
    "        'croatian_vocabulary': 0.3,\n",
    "        'sentence_structure': 0.2,\n",
    "        'cultural_context': 0.2\n",
    "    }\n",
    "    \n",
    "    quality_scores['overall'] = sum(\n",
    "        score * weights[metric] \n",
    "        for metric, score in quality_scores.items() \n",
    "        if metric in weights\n",
    "    )\n",
    "    \n",
    "    return quality_scores\n",
    "\n",
    "# Test Croatian quality assessment\n",
    "test_texts = {\n",
    "    \"High Quality Croatian\": \"Zagreb je glavni i najveći grad Republike Hrvatske, smješten na sjeverozapadu zemlje uz rijeku Savu. Grad je važno političko, gospodarsko i kulturno središte, te dom mnogih značajnih institucija i kulturnih znamenitosti.\",\n",
    "    \n",
    "    \"Medium Quality\": \"Zagreb je glavni grad Hrvatske. Ima puno stanovnika i nalazi se u hrvatskoj. Grad je poznat po svojoj ljepoti.\",\n",
    "    \n",
    "    \"Low Quality (No Diacritics)\": \"Zagreb je glavni grad Hrvatske. Grad ima puno stanovnika i poznat je po svojoj lepoti i kulturi.\",\n",
    "    \n",
    "    \"Cultural Context Rich\": \"Dubrovnik, poznat kao 'biser Jadrana', je grad s bogatom povijesti smješten u Dalmaciji. UNESCO je uvrstio Dubrovnik na popis svjetske baštine zbog njegovih izuzetnih kulturnih vrijednosti.\"\n",
    "}\n",
    "\n",
    "print(\"🇭🇷 Croatian Language Quality Assessment:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "quality_results = []\n",
    "\n",
    "for category, text in test_texts.items():\n",
    "    scores = assess_croatian_quality(text)\n",
    "    \n",
    "    print(f\"\\n📝 {category}:\")\n",
    "    print(f\"Text: {text[:80]}...\")\n",
    "    print(f\"\\n📊 Quality Scores:\")\n",
    "    \n",
    "    for metric, score in scores.items():\n",
    "        if metric != 'overall':\n",
    "            print(f\"  {metric.replace('_', ' ').title()}: {score:.3f}\")\n",
    "    \n",
    "    print(f\"  🎯 Overall Quality: {scores['overall']:.3f}\")\n",
    "    \n",
    "    # Quality rating\n",
    "    overall = scores['overall']\n",
    "    if overall >= 0.8:\n",
    "        rating = \"🟢 Excellent\"\n",
    "    elif overall >= 0.6:\n",
    "        rating = \"🟡 Good\"\n",
    "    elif overall >= 0.4:\n",
    "        rating = \"🟠 Fair\"\n",
    "    else:\n",
    "        rating = \"🔴 Poor\"\n",
    "    \n",
    "    print(f\"  Rating: {rating}\")\n",
    "    \n",
    "    quality_results.append({\n",
    "        'category': category,\n",
    "        'overall_score': scores['overall'],\n",
    "        'scores': scores\n",
    "    })\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Visualize quality assessment\n",
    "categories = [r['category'] for r in quality_results]\n",
    "overall_scores = [r['overall_score'] for r in quality_results]\n",
    "\n",
    "# Detailed scores breakdown\n",
    "metrics = ['diacritic_usage', 'croatian_vocabulary', 'sentence_structure', 'cultural_context']\n",
    "metric_scores = {metric: [r['scores'][metric] for r in quality_results] for metric in metrics}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Overall quality scores\n",
    "bars = ax1.barh(categories, overall_scores, color=['green', 'orange', 'red', 'blue'])\n",
    "ax1.set_title('Overall Croatian Quality Scores', weight='bold')\n",
    "ax1.set_xlabel('Quality Score')\n",
    "ax1.set_xlim(0, 1)\n",
    "\n",
    "for bar, score in zip(bars, overall_scores):\n",
    "    ax1.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "             f'{score:.3f}', ha='left', va='center', weight='bold')\n",
    "\n",
    "# Quality metrics breakdown\n",
    "x = np.arange(len(categories))\n",
    "width = 0.2\n",
    "colors = ['lightblue', 'lightgreen', 'lightsalmon', 'plum']\n",
    "\n",
    "for i, (metric, scores) in enumerate(metric_scores.items()):\n",
    "    ax2.bar(x + i * width, scores, width, label=metric.replace('_', ' ').title(), color=colors[i])\n",
    "\n",
    "ax2.set_title('Quality Metrics Breakdown', weight='bold')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_xlabel('Text Category')\n",
    "ax2.set_xticks(x + width * 1.5)\n",
    "ax2.set_xticklabels([cat.replace(' ', '\\n') for cat in categories], fontsize=8)\n",
    "ax2.legend(fontsize=8)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Croatian quality assessment complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices and Optimization\n",
    "\n",
    "Key lessons learned for Croatian RAG generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices summary\n",
    "best_practices = {\n",
    "    \"Prompt Engineering\": {\n",
    "        \"✅ Do\": [\n",
    "            \"Use Croatian system prompts consistently\",\n",
    "            \"Include cultural context instructions\", \n",
    "            \"Specify formal Croatian language style\",\n",
    "            \"Match prompt template to query type\",\n",
    "            \"Preserve diacritic encoding throughout\"\n",
    "        ],\n",
    "        \"❌ Don't\": [\n",
    "            \"Mix languages in system prompts\",\n",
    "            \"Ignore Croatian cultural context\",\n",
    "            \"Use generic English templates\",\n",
    "            \"Assume model understands Croatian nuances\"\n",
    "        ]\n",
    "    },\n",
    "    \"Model Configuration\": {\n",
    "        \"✅ Do\": [\n",
    "            \"Set temperature 0.6-0.8 for Croatian\",\n",
    "            \"Use sufficient max tokens (1500-2000)\",\n",
    "            \"Enable diacritic preservation\",\n",
    "            \"Configure timeout for longer responses\"\n",
    "        ],\n",
    "        \"❌ Don't\": [\n",
    "            \"Use too low temperature (rigid responses)\",\n",
    "            \"Use too high temperature (inconsistent quality)\",\n",
    "            \"Limit tokens too strictly\",\n",
    "            \"Ignore Croatian-specific settings\"\n",
    "        ]\n",
    "    },\n",
    "    \"Response Processing\": {\n",
    "        \"✅ Do\": [\n",
    "            \"Parse and validate Croatian content\",\n",
    "            \"Check for diacritic preservation\",\n",
    "            \"Assess cultural context accuracy\",\n",
    "            \"Monitor confidence scores\",\n",
    "            \"Extract and validate source references\"\n",
    "        ],\n",
    "        \"❌ Don't\": [\n",
    "            \"Accept responses without validation\",\n",
    "            \"Ignore language detection results\",\n",
    "            \"Skip quality assessment\",\n",
    "            \"Trust confidence scores blindly\"\n",
    "        ]\n",
    "    },\n",
    "    \"Performance Optimization\": {\n",
    "        \"✅ Do\": [\n",
    "            \"Cache common Croatian patterns\",\n",
    "            \"Batch similar query types\",\n",
    "            \"Monitor generation times\",\n",
    "            \"Optimize context length\",\n",
    "            \"Use async processing for scalability\"\n",
    "        ],\n",
    "        \"❌ Don't\": [\n",
    "            \"Generate synchronously for multiple queries\",\n",
    "            \"Ignore performance metrics\",\n",
    "            \"Use excessive context length\",\n",
    "            \"Skip error handling\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"🎯 Croatian RAG Generation Best Practices:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"\\n📚 {category}:\")\n",
    "    \n",
    "    if \"✅ Do\" in practices:\n",
    "        print(\"\\n✅ Best Practices:\")\n",
    "        for practice in practices[\"✅ Do\"]:\n",
    "            print(f\"  • {practice}\")\n",
    "    \n",
    "    if \"❌ Don't\" in practices:\n",
    "        print(\"\\n❌ Avoid:\")\n",
    "        for practice in practices[\"❌ Don't\"]:\n",
    "            print(f\"  • {practice}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Performance optimization tips\n",
    "print(\"\\n⚡ Performance Optimization Tips:\")\n",
    "optimization_tips = [\n",
    "    \"Use llama3.1:8b for best Croatian support vs speed balance\",\n",
    "    \"Implement response caching for repeated queries\",\n",
    "    \"Batch process multiple queries when possible\",\n",
    "    \"Monitor GPU/CPU usage during generation\",\n",
    "    \"Set appropriate timeout values (30-60s)\",\n",
    "    \"Use streaming for long responses\",\n",
    "    \"Implement fallback strategies for failures\"\n",
    "]\n",
    "\n",
    "for tip in optimization_tips:\n",
    "    print(f\"  🔧 {tip}\")\n",
    "\n",
    "print(\"\\n📈 Quality Improvement Strategies:\")\n",
    "quality_tips = [\n",
    "    \"Regularly assess Croatian diacritic usage\",\n",
    "    \"Monitor cultural context accuracy\",\n",
    "    \"Track confidence score distributions\",\n",
    "    \"Validate source reference extraction\",\n",
    "    \"Test with diverse Croatian query types\",\n",
    "    \"Implement human feedback loops\",\n",
    "    \"Update prompt templates based on performance\"\n",
    "]\n",
    "\n",
    "for tip in quality_tips:\n",
    "    print(f\"  📊 {tip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished in Step 4\n",
    "\n",
    "✅ **Ollama Integration**: Built robust client for local LLM processing\n",
    "\n",
    "✅ **Croatian Prompt Engineering**: Created specialized templates for different query types\n",
    "\n",
    "✅ **Response Quality Assessment**: Implemented Croatian language quality metrics\n",
    "\n",
    "✅ **Performance Monitoring**: Added comprehensive generation tracking\n",
    "\n",
    "✅ **Cultural Context**: Integrated Croatian cultural awareness throughout\n",
    "\n",
    "### Key Technical Achievements\n",
    "\n",
    "1. **Local LLM Processing**: Complete privacy and control over generation\n",
    "2. **Croatian Language Support**: Diacritic preservation and cultural context\n",
    "3. **Adaptive Prompting**: Different templates for different query types\n",
    "4. **Quality Assessment**: Multi-metric evaluation system\n",
    "5. **Performance Optimization**: Async processing and monitoring\n",
    "\n",
    "### Next: Step 5 - Complete Pipeline Integration\n",
    "\n",
    "In the final step, we'll integrate all components into a complete RAG system:\n",
    "\n",
    "- **End-to-End Pipeline**: Connect preprocessing → vector DB → retrieval → generation\n",
    "- **System Orchestration**: Manage the complete workflow\n",
    "- **Error Handling**: Robust failure recovery\n",
    "- **Performance Optimization**: System-wide efficiency improvements\n",
    "- **Evaluation Framework**: Complete system assessment\n",
    "\n",
    "The generation system is now ready to produce high-quality Croatian responses using retrieved context. Let's move on to integrate everything into our final RAG pipeline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}